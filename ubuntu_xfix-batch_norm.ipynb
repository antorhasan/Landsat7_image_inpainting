{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "K0JU1wEzOH07",
    "outputId": "ec3065cd-da37-40ce-8763-cda85a3a6cf8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import cv2\n",
    "#import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")    #for tensorboard\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "agRyZL61OH1P"
   },
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    features = {\n",
    "                \"image_y\": tf.FixedLenFeature((), tf.string ),\n",
    "                \"image_m\": tf.FixedLenFeature((), tf.string )\n",
    "                #\"image_x\": tf.FixedLenFeature((), tf.string )\n",
    "                }\n",
    "\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    \n",
    "    image_y = tf.decode_raw(parsed_features[\"image_y\"],  tf.float64)\n",
    "    image_m = tf.decode_raw(parsed_features[\"image_m\"],  tf.float64)\n",
    "    #image_x = tf.decode_raw(parsed_features[\"image_x\"],  tf.float64)\n",
    "    \n",
    "    image_y = tf.cast(image_y,dtype=tf.float32)\n",
    "    image_m = tf.cast(image_m,dtype=tf.float32)\n",
    "    #image_x = tf.cast(image_x,dtype=tf.float32)\n",
    "    \n",
    "    image_y = tf.reshape(image_y, [512,512,1])\n",
    "    image_m = tf.reshape(image_m, [512,512,1])\n",
    "    #image_x = tf.reshape(image_x, [512,512,1])\n",
    "    \n",
    "    return image_y,image_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(inputs, is_training, decay=.99, epsilon=0.00000001):\n",
    "    with tf.name_scope(\"batch_norm\") as scope:\n",
    "\n",
    "\n",
    "        scale = tf.get_variable(\"scale_BN\", (inputs.get_shape()[1:4]), initializer=tf.ones_initializer())\n",
    "        beta = tf.get_variable(\"beta_BN\", (inputs.get_shape()[1:4]), initializer=tf.zeros_initializer())\n",
    "        pop_mean = tf.get_variable(\"pop_mean\", (inputs.get_shape()[1:4]), initializer=tf.zeros_initializer(), trainable=False)\n",
    "        pop_var = tf.get_variable(\"pop_var\", (inputs.get_shape()[1:4]), initializer=tf.ones_initializer(), trainable=False)\n",
    "\n",
    "        mean = tf.cond(tf.cast(is_training,tf.bool), lambda: tf.nn.moments(inputs,[0])[0], lambda: tf.multiply(tf.ones(inputs.get_shape()[1:4]), pop_mean))\n",
    "        var = tf.cond(tf.cast(is_training,tf.bool), lambda: tf.nn.moments(inputs,[0])[1], lambda: tf.multiply(tf.ones(inputs.get_shape()[-1]), pop_var))\n",
    "        train_mean = tf.cond(tf.cast(is_training,tf.bool), lambda:tf.assign(pop_mean, pop_mean*decay+mean*(1-decay)),lambda:tf.zeros(1))\n",
    "        train_var = tf.cond(tf.cast(is_training,tf.bool),lambda:tf.assign(pop_var, pop_var*decay+var*(1-decay)),lambda:tf.zeros(1))\n",
    "\n",
    "        with tf.control_dependencies([train_mean, train_var]):\n",
    "            return tf.nn.batch_normalization(inputs, mean, var, beta, scale, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZZqe6faCOH1R"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def partial_conv(pixel, mask,is_training, kernel_size, filter_numbers, stride, batch_n, nonlinearity, trans):\n",
    "\n",
    "    with tf.name_scope(\"part_conv\") as scope:\n",
    "        kernel_h = kernel_size[0]\n",
    "        kernel_w = kernel_size[1]\n",
    "        if trans==True:\n",
    "            kernel_d = filter_numbers\n",
    "            kernel_o = pixel.get_shape().as_list()[3]\n",
    "        elif trans==False:\n",
    "            kernel_d = pixel.get_shape().as_list()[3]\n",
    "            kernel_o = filter_numbers\n",
    "        elif trans==\"same_pad\":\n",
    "            kernel_d = pixel.get_shape().as_list()[3]\n",
    "            kernel_o = filter_numbers\n",
    "            \n",
    "        W = tf.get_variable('Weights', (kernel_h, kernel_w, kernel_d, kernel_o),\n",
    "                            initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "        W1 = tf.ones((kernel_h, kernel_w, kernel_d, kernel_o), name='Weights_mask')\n",
    "\n",
    "        Z1 = tf.multiply(pixel, mask, name=\"element_op\")\n",
    "\n",
    "        if trans==True:\n",
    "            #need to fix for variable last batch size. The last mini_batch will be of different size most of the time\n",
    "            out_shape_list = pixel.get_shape().as_list()\n",
    "            out_shape_list[1] = pixel.get_shape().as_list()[1] + 2\n",
    "            out_shape_list[2] = pixel.get_shape().as_list()[2] + 2\n",
    "            out_shape_list[3] = filter_numbers\n",
    "            out_shape = tf.constant(out_shape_list)\n",
    "            #out_shape = tf.TensorShape(out_shape_list)\n",
    "            #out_shape = tf.cast(out_shape,tf.int32)\n",
    "            prime_conv = tf.nn.conv2d_transpose(Z1, W,out_shape, strides=stride, padding=\"VALID\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d_transpose(mask, W1,output_shape=tf.TensorShape(out_shape_list), strides=stride, padding=\"VALID\", name=\"sec_conv\")\n",
    "        elif trans==False:\n",
    "            prime_conv = tf.nn.conv2d(Z1, W, strides=stride, padding=\"VALID\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d(mask, W1, strides=stride, padding=\"VALID\", name=\"sec_conv\")\n",
    "        elif trans==\"same_pad\":\n",
    "            prime_conv = tf.nn.conv2d(Z1, W, strides=stride, padding=\"SAME\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d(mask, W1, strides=stride, padding=\"SAME\", name=\"sec_conv\")\n",
    "\n",
    "\n",
    "        inver_sum = tf.divide(tf.constant(1.0), sec_conv)\n",
    "        clean_sum = tf.where(tf.is_inf(inver_sum), tf.zeros_like(inver_sum), inver_sum)\n",
    "\n",
    "        weighted_pixel = tf.multiply(prime_conv, clean_sum, name=\"multi_inver_sum\")\n",
    "        up_mask = tf.where(tf.not_equal(sec_conv, tf.constant(0.0)),tf.ones_like(sec_conv),sec_conv)\n",
    "\n",
    "        #normalized_out = tf.cond(tf.cast(batch_n,tf.bool), lambda:batch_norm(weighted_pixel, is_training), lambda:weighted_pixel)\n",
    "        \n",
    "        normalized_out = weighted_pixel\n",
    "        \n",
    "        if nonlinearity==\"relu\":\n",
    "            up_pixel = tf.nn.relu(normalized_out, name=\"relu\")\n",
    "        elif nonlinearity==\"leaky_relu\":\n",
    "            up_pixel = tf.nn.leaky_relu(normalized_out, name=\"leaky_relu\")\n",
    "        elif nonlinearity==\"none\":\n",
    "            up_pixel = normalized_out\n",
    "            #up_pixel = tf.sigmoid(normalized_out)\n",
    "            #up_pixel = tf.nn.relu(normalized_out, name=\"relu\")\n",
    "            \n",
    "        tf.summary.histogram(\"weights\", W)    \n",
    "        tf.summary.histogram(\"activations\", up_pixel)   \n",
    "        \n",
    "        return up_pixel, up_mask\n",
    "    \n",
    "\n",
    "\n",
    "def place_holders(mini_size,height, width, channels):\n",
    "    #X = tf.placeholder(tf.float32, shape=(mini_size, height, width, channels))\n",
    "    Y = tf.placeholder(tf.float32, shape=(mini_size, height, width, channels))\n",
    "    M = tf.placeholder(tf.float32, shape=(mini_size, height, width, channels))\n",
    "    return M ,Y\n",
    "\n",
    "\n",
    "def near_up_sampling(pixel, mask, output_size):\n",
    "    with tf.name_scope(\"nearest_up\") as scope:\n",
    "        up_pixel = tf.image.resize_nearest_neighbor(pixel, size=output_size, name=\"nearest_pixel_up\")\n",
    "        up_mask = tf.image.resize_nearest_neighbor(pixel, size=output_size, name=\"nearest_mask_up\")\n",
    "        return up_pixel, up_mask\n",
    "\n",
    "def concat(near_pixel, pconv_pixel, near_mask, pconv_mask):\n",
    "    with tf.name_scope(\"concatenation\") as scope:\n",
    "        up_pixel = tf.concat([pconv_pixel, near_pixel], axis=3)\n",
    "        up_mask = tf.concat([pconv_mask,near_mask], axis=3)\n",
    "        return up_pixel, up_mask\n",
    "\n",
    "def decoding_layer(pixel_in,mask_in,is_training, output_size_in, pconv_pixel1, pconv_mask1, filter_numbers1):\n",
    "    with tf.name_scope(\"decoding\") as scope:\n",
    "        near_pixel1,near_mask1 = near_up_sampling(pixel_in,mask_in,output_size_in)\n",
    "        concat_pixel,concat_mask = concat(near_pixel1, pconv_pixel1, near_mask1, pconv_mask1)\n",
    "        pixel_out,mask_out = partial_conv(concat_pixel,concat_mask,is_training,[3,3],filter_numbers1,[1,1,1,1],\n",
    "                                        True,\"leaky_relu\",trans=True)\n",
    "        return pixel_out,mask_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mFUVWDrVOH1V"
   },
   "outputs": [],
   "source": [
    "def forward_prop(is_training, pixel, mask):\n",
    "\n",
    "    with tf.variable_scope(\"PConv1\") as scope:\n",
    "        p_out1,m_out1 = partial_conv(pixel,mask,is_training,kernel_size=[7,7],filter_numbers=64,stride=[1,2,2,1],\n",
    "                                    batch_n=False,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv2\") as scope:\n",
    "        p_out2,m_out2 = partial_conv(p_out1,m_out1,is_training,kernel_size=[5,5],filter_numbers=128,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv3\") as scope:\n",
    "        p_out3,m_out3 = partial_conv(p_out2,m_out2,is_training,kernel_size=[5,5],filter_numbers=256,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv4\") as scope:\n",
    "        p_out4,m_out4 = partial_conv(p_out3,p_out3,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv5\") as scope:\n",
    "        p_out5,m_out5 = partial_conv(p_out4,m_out4,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv6\") as scope:\n",
    "        p_out6,m_out6 = partial_conv(p_out5,m_out5,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv7\") as scope:\n",
    "        p_out7,m_out7 = partial_conv(p_out6,m_out6,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,1,1,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv8\") as scope:\n",
    "        p_out8,m_out8 = partial_conv(p_out7,m_out7,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,1,1,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"decoding9\") as scope:\n",
    "        p_out9,m_out9 = decoding_layer(p_out8,m_out8,is_training,(p_out7.get_shape().as_list()[1],p_out7.get_shape().as_list()[2]),\n",
    "                                        p_out7,m_out7,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding10\") as scope:\n",
    "        p_out10,m_out10 = decoding_layer(p_out9,m_out9,is_training,(p_out6.get_shape().as_list()[1],p_out6.get_shape().as_list()[2]),\n",
    "                                        p_out6,m_out6,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding11\") as scope:\n",
    "        p_out11,m_out11 = decoding_layer(p_out10,m_out10,is_training,(p_out5.get_shape().as_list()[1],p_out5.get_shape().as_list()[2]),\n",
    "                                        p_out5,m_out5,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding12\") as scope:\n",
    "        p_out12,m_out12 = decoding_layer(p_out11,m_out11,is_training,(p_out4.get_shape().as_list()[1],p_out4.get_shape().as_list()[2]),\n",
    "                                        p_out4,m_out4,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding13\") as scope:\n",
    "        p_out13,m_out13 = decoding_layer(p_out12,m_out12,is_training,(p_out3.get_shape().as_list()[1],p_out3.get_shape().as_list()[2]),\n",
    "                                        p_out3,m_out3,filter_numbers1=256)\n",
    "\n",
    "    with tf.variable_scope(\"decoding14\") as scope:\n",
    "        p_out14,m_out14 = decoding_layer(p_out13,m_out13,is_training,(p_out2.get_shape().as_list()[1],p_out2.get_shape().as_list()[2]),\n",
    "                                        p_out2,m_out2,filter_numbers1=128)\n",
    "\n",
    "    with tf.variable_scope(\"decoding15\") as scope:\n",
    "        p_out15,m_out15 = decoding_layer(p_out14,m_out14,is_training,(p_out1.get_shape().as_list()[1],p_out1.get_shape().as_list()[2]),\n",
    "                                        p_out1,m_out1,filter_numbers1=64)\n",
    "\n",
    "    with tf.variable_scope(\"decoding16\") as scope:\n",
    "        near_pixel1,near_mask1 = near_up_sampling(p_out15,m_out15,(pixel.get_shape().as_list()[1],pixel.get_shape().as_list()[2]))\n",
    "        concat_pixel,concat_mask = concat(near_pixel1, pixel, near_mask1, mask)\n",
    "        pixel_out,mask_out = partial_conv(concat_pixel,concat_mask,is_training,[3,3],filter_numbers=1,stride=[1,1,1,1],\n",
    "                                        batch_n=False,nonlinearity=\"none\",trans=\"same_pad\")\n",
    "        return pixel_out,mask_out\n",
    "\n",
    "\n",
    "\n",
    "def compute_cost(pixel_gt,mask_gt,pixel_pre,hole_pera):\n",
    "    loss_valid = tf.losses.absolute_difference(tf.multiply(pixel_gt,mask_gt),tf.multiply(pixel_pre,mask_gt), weights=1.0,\n",
    "                                                reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)\n",
    "    loss_hole = tf.losses.absolute_difference(tf.multiply(pixel_gt,(1-mask_gt)),tf.multiply(pixel_pre,(1-mask_gt)), weights=1.0,\n",
    "                                                reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)\n",
    "\n",
    "    total_loss = (loss_valid + tf.multiply(hole_pera,loss_hole))/7.0\n",
    "    \n",
    "    tf.summary.scalar('loss',total_loss)\n",
    "   \n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lgvAO8mGOH1d"
   },
   "outputs": [],
   "source": [
    "def model(learning_rate,num_epochs,mini_size):\n",
    "    #ops.reset_default_graph()\n",
    "#     m = x_train.shape[0]\n",
    "#     h = x_train.shape[1]\n",
    "#     w = x_train.shape[2]\n",
    "#     c = x_train.shape[3]\n",
    "    m = 9882\n",
    "    #m = 8\n",
    "    h = 512\n",
    "    w = 512\n",
    "    c = 1\n",
    "    \n",
    "    m_val_size = 1098\n",
    "    #m_val_size = 2\n",
    "    costs = []\n",
    "\n",
    "    M,Y = place_holders(mini_size,h, w, c)\n",
    "    \n",
    "    tf.summary.image(\"input_Y\",Y,3)\n",
    "    tf.summary.image(\"input_M\",M,3)\n",
    "    \n",
    "    is_training = tf.placeholder(tf.bool,name=\"training\")\n",
    "    \n",
    "    pixel_out, mask_out = forward_prop(is_training,pixel=Y, mask=M)\n",
    "\n",
    "    cost = compute_cost(pixel_gt=Y, mask_gt=M, pixel_pre=pixel_out, hole_pera=6.0)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    #data_x = tf.placeholder(x_train.dtype, x_train.shape)\n",
    "    #data_m = tf.placeholder(m_train.dtype, m_train.shape)\n",
    "    #data_y = tf.placeholder(y_train.dtype, y_train.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    filenames = \"/media/antor/Files/ML/Papers/train_new.tfrecords\"\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    #dataset = tf.data.Dataset.from_tensor_slices((data_x, data_m, data_y))\n",
    "    \n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.shuffle(20)\n",
    "    dataset = dataset.batch(mini_size)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "    num_mini = int(m/mini_size)          #must keep this fully divided and num_mini output as int pretty sure it doesn't need\n",
    "                                    #to be an int\n",
    "    \n",
    "    merge_sum = tf.summary.merge_all()\n",
    "    #l1_summary = tf.summary.scalar('L1', cost)            #for tensorboard\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())   #for tensorboard\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "    #session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    #sess.run(iterator.initializer, feed_dict={data_x:x_train, data_m:m_train, data_y:y_train})\n",
    "    sess.run(iterator.initializer)\n",
    "    mini_cost = 0.0\n",
    "    counter = 1\n",
    "    while True:\n",
    "        try:\n",
    "            pix_gt, mask_in = sess.run(next_element)\n",
    "            pix_gt = tf.reshape(pix_gt,[mini_size,512,512,1])\n",
    "            mask_in = tf.reshape(mask_in,[mini_size,512,512,1])\n",
    "            #pix_in = tf.reshape(pix_in,[mini_size,512,512,1])\n",
    "            \n",
    "            pix_gt = pix_gt.eval(session=sess)\n",
    "            mask_in = mask_in.eval(session=sess)\n",
    "            #pix_in = pix_in.eval(session=sess)\n",
    "            #print( pix_gt)\n",
    "            #print( mask_in)\n",
    "            #print( pix_in)\n",
    "            #pixel_out, mask_out = forward_prop(True,pixel=label_in, mask=mask_in)\n",
    "\n",
    "            #cost = compute_cost(pixel_gt=pix_in, mask_gt=mask_in, pixel_pre=pixel_out, hole_pera=6.0)\n",
    "\n",
    "            #optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "            \n",
    "            _ , temp_cost = sess.run([optimizer,cost],feed_dict={M:mask_in, Y:pix_gt, is_training:True})\n",
    "            #_ , temp_cost = sess.run([optimizer,cost])\n",
    "            \n",
    "            #mini_cost += temp_cost/num_mini\n",
    "            mini_cost += temp_cost/10\n",
    "            if counter%5 == 0:\n",
    "                s = sess.run(merge_sum, feed_dict={M:mask_in, Y:pix_gt, is_training:True})\n",
    "                file_writer.add_summary(s,counter)\n",
    "            \n",
    "            if counter%num_mini==0:\n",
    "                print(\"cost after epoch \" + str(counter/num_mini) + \": \" + str(mini_cost))\n",
    "                mini_cost =0.0 \n",
    "            #print(\"cost after epoch \" + str(counter/num_mini) + \": \" + str(mini_cost))\n",
    "            \n",
    "#             if counter%50==0:         #for tensorboard\n",
    "#                 summary_str = l1_summary.eval(session=sess,feed_dict={M:mask_in, Y:pix_gt, is_training:True})\n",
    "#                 #step = int(counter%num_mini) * n_batches + batch_index\n",
    "#                 file_writer.add_summary(summary_str, counter)\n",
    "            \n",
    "            #if counter%1==0:\n",
    "            #    print(\"mini batch cost of batch \" + str(counter) + \" is : \" + str(temp_cost))\n",
    "            if counter%10==0:\n",
    "                print(\"mini batch cost of batch \" + str(counter) + \" is : \" + str(mini_cost))\n",
    "                mini_cost =0.0 \n",
    "            \n",
    "            if counter==200:\n",
    "                break\n",
    "            \n",
    "            counter = counter + 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            #counter = counter + 1\n",
    "            #print(\"cost after epoch \" + str(counter) + \": \" + str(mini_cost))\n",
    "            #mini_cost = 0.0\n",
    "            break\n",
    "    \n",
    "    file_writer.close()            #for tensorboard\n",
    "    #data_x_val = tf.placeholder(x_val.dtype, x_val.shape)\n",
    "    #m_val = m_val.astype(float)\n",
    "    #data_m_val = tf.placeholder(m_val.dtype, m_val.shape)\n",
    "    #data_y_val = tf.placeholder(y_val.dtype, y_val.shape)\n",
    "    \n",
    "    filenames_val = \"/media/antor/Files/ML/Papers/val_new.tfrecords\"\n",
    "    dataset_val = tf.data.TFRecordDataset(filenames_val)\n",
    "    dataset_val = dataset_val.map(_parse_function)\n",
    "    \n",
    "    #dataset_val = tf.data.Dataset.from_tensor_slices((data_x_val,data_m_val,data_y_val))\n",
    "    dataset_val = dataset_val.shuffle(20)\n",
    "    dataset_val = dataset_val.batch(mini_size)\n",
    "    \n",
    "    iterator_val = dataset_val.make_initializable_iterator()\n",
    "    next_element_val = iterator_val.get_next()\n",
    "    num_mini_val = int(m_val_size/mini_size)\n",
    "\n",
    "    counter_val = 1\n",
    "    #sess.run(iterator_val.initializer, feed_dict={data_x_val:x_val,data_m_val:m_val,data_y_val:y_val})\n",
    "    sess.run(iterator_val.initializer)\n",
    "    mini_cost_val = 0.0\n",
    "    break_num = 50\n",
    "    while True:\n",
    "        try:\n",
    "            label_in_val, mask_in_val = sess.run(next_element_val)\n",
    "            #pix_in_val = tf.reshape(pix_in_val,[mini_size,512,512,1])\n",
    "            mask_in_val = tf.reshape(mask_in_val,[mini_size,512,512,1])\n",
    "            label_in_val = tf.reshape(label_in_val,[mini_size,512,512,1])\n",
    "            #pix_in_val = pix_in_val.eval(session=sess)\n",
    "            mask_in_val = mask_in_val.eval(session=sess)\n",
    "            label_in_val = label_in_val.eval(session=sess)\n",
    "            \n",
    "            temp_cost_val = sess.run(cost, feed_dict={M:mask_in_val,Y:label_in_val,is_training:False})\n",
    "            \n",
    "            \n",
    "            mini_cost_val += temp_cost_val/break_num\n",
    "            \n",
    "            if counter_val%num_mini_val==0:\n",
    "                print(\"cost after epoch \" + str(counter_val/num_mini_val) + \": \" + str(mini_cost_val))\n",
    "                mini_cost_val =0.0 \n",
    "            counter_val = counter_val + 1\n",
    "            \n",
    "            if counter_val==break_num:\n",
    "                print(\"cost of val_set \" + \": \" + str(mini_cost_val))\n",
    "                break\n",
    "            \n",
    "            \n",
    "        except tf.errors.OutOfRangeError:\n",
    "\n",
    "            #print(\"validation cost after epoch \" + \"1\" + \": \" + str(mini_cost_val))\n",
    "\n",
    "            break\n",
    "    \n",
    "    #save_path = saver.save(sess, \"/home/antor/Downloads/model_checkpoint/my_model_final.ckpt\")\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "i5w7yUdWOH1h",
    "outputId": "a3dd9e34-f947-4e9c-be22-f5437697dd5f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini batch cost of batch 10 is : 0.23687545359134668\n",
      "mini batch cost of batch 20 is : 0.16352798864245413\n",
      "mini batch cost of batch 30 is : 0.12338984459638595\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Nan in summary histogram for: decoding16/part_conv/weights\n\t [[Node: decoding16/part_conv/weights = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](decoding16/part_conv/weights/tag, decoding16/Weights/read/_31)]]\n\t [[Node: PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer/_62 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_93_PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer)]]\n\nCaused by op 'decoding16/part_conv/weights', defined at:\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2907, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-7b76b33cba70>\", line 1, in <module>\n    model(learning_rate=.055,num_epochs=1,mini_size=2)\n  File \"<ipython-input-6-6b8a3d687df7>\", line 24, in model\n    pixel_out, mask_out = forward_prop(is_training,pixel=Y, mask=M)\n  File \"<ipython-input-5-dd4d1e07c96f>\", line 59, in forward_prop\n    batch_n=False,nonlinearity=\"none\",trans=\"same_pad\")\n  File \"<ipython-input-4-104aef059671>\", line 63, in partial_conv\n    tf.summary.histogram(\"weights\", W)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/summary/summary.py\", line 187, in histogram\n    tag=tag, values=values, name=scope)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 283, in histogram_summary\n    \"HistogramSummary\", tag=tag, values=values, name=name)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: decoding16/part_conv/weights\n\t [[Node: decoding16/part_conv/weights = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](decoding16/part_conv/weights/tag, decoding16/Weights/read/_31)]]\n\t [[Node: PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer/_62 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_93_PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: decoding16/part_conv/weights\n\t [[Node: decoding16/part_conv/weights = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](decoding16/part_conv/weights/tag, decoding16/Weights/read/_31)]]\n\t [[Node: PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer/_62 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_93_PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7b76b33cba70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.055\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmini_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-6b8a3d687df7>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(learning_rate, num_epochs, mini_size)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mmini_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtemp_cost\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmask_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpix_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: decoding16/part_conv/weights\n\t [[Node: decoding16/part_conv/weights = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](decoding16/part_conv/weights/tag, decoding16/Weights/read/_31)]]\n\t [[Node: PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer/_62 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_93_PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer)]]\n\nCaused by op 'decoding16/part_conv/weights', defined at:\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2907, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-7b76b33cba70>\", line 1, in <module>\n    model(learning_rate=.055,num_epochs=1,mini_size=2)\n  File \"<ipython-input-6-6b8a3d687df7>\", line 24, in model\n    pixel_out, mask_out = forward_prop(is_training,pixel=Y, mask=M)\n  File \"<ipython-input-5-dd4d1e07c96f>\", line 59, in forward_prop\n    batch_n=False,nonlinearity=\"none\",trans=\"same_pad\")\n  File \"<ipython-input-4-104aef059671>\", line 63, in partial_conv\n    tf.summary.histogram(\"weights\", W)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/summary/summary.py\", line 187, in histogram\n    tag=tag, values=values, name=scope)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 283, in histogram_summary\n    \"HistogramSummary\", tag=tag, values=values, name=name)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/antor/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: decoding16/part_conv/weights\n\t [[Node: decoding16/part_conv/weights = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](decoding16/part_conv/weights/tag, decoding16/Weights/read/_31)]]\n\t [[Node: PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer/_62 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_93_PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](PConv1/part_conv/relu-1-1-TransposeNCHWToNHWC-LayoutOptimizer)]]\n"
     ]
    }
   ],
   "source": [
    "model(learning_rate=.055,num_epochs=1,mini_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Kq5tG1I0OH1o"
   },
   "outputs": [],
   "source": [
    "#habijabi\n",
    "#newh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "I82s6e35OH1t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "landsat_image _inpaintingerere.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
