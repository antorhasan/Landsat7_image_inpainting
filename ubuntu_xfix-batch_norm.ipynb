{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "K0JU1wEzOH07",
    "outputId": "ec3065cd-da37-40ce-8763-cda85a3a6cf8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import gc\n",
    "#import cv2\n",
    "#import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")    #for tensorboard\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "agRyZL61OH1P"
   },
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    \n",
    "        \n",
    "        \n",
    "    features = {\n",
    "                \"image_y\": tf.FixedLenFeature((), tf.string ),\n",
    "                \"image_m\": tf.FixedLenFeature((), tf.string )\n",
    "                #\"image_x\": tf.FixedLenFeature((), tf.string )\n",
    "                }\n",
    "\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "\n",
    "    image_y = tf.decode_raw(parsed_features[\"image_y\"],  tf.float64)\n",
    "    image_m = tf.decode_raw(parsed_features[\"image_m\"],  tf.float64)\n",
    "\n",
    "    image_y = tf.reshape(image_y, [256,256,1])\n",
    "    image_m = tf.reshape(image_m, [256,256,1])\n",
    "    #image_x = tf.decode_raw(parsed_features[\"image_x\"],  tf.float64)\n",
    "    #tf.summary.image(\"64_Y\",image_y,3)\n",
    "    #tf.summary.image(\"64_M\",image_m,3)\n",
    "\n",
    "    image_y = tf.cast(image_y,dtype=tf.float32)\n",
    "    image_m = tf.cast(image_m,dtype=tf.float32)\n",
    "    #image_x = tf.cast(image_x,dtype=tf.float32)\n",
    "    #tf.summary.image(\"32_Y\",image_y,3)\n",
    "    #tf.summary.image(\"32_M\",image_m,3)\n",
    "\n",
    "    #image_y = tf.reshape(image_y, [512,512,1])\n",
    "    #image_m = tf.reshape(image_m, [512,512,1])\n",
    "    #image_x = tf.reshape(image_x, [512,512,1])\n",
    "\n",
    "    return image_y,image_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(inputs, is_training, decay=.5, epsilon=0.00000001):\n",
    "    with tf.name_scope(\"batch_norm\") as scope:\n",
    "\n",
    "\n",
    "        scale = tf.get_variable(\"scale_BN\", (inputs.get_shape()[1:4]), initializer=tf.ones_initializer())\n",
    "        beta = tf.get_variable(\"beta_BN\", (inputs.get_shape()[1:4]), initializer=tf.zeros_initializer())\n",
    "        pop_mean = tf.get_variable(\"pop_mean\", (inputs.get_shape()[1:4]), initializer=tf.zeros_initializer(), trainable=False)\n",
    "        pop_var = tf.get_variable(\"pop_var\", (inputs.get_shape()[1:4]), initializer=tf.ones_initializer(), trainable=False)\n",
    "\n",
    "        mean = tf.cond(tf.cast(is_training,tf.bool), lambda: tf.nn.moments(inputs,[0])[0], lambda: tf.multiply(tf.ones(inputs.get_shape()[1:4]), pop_mean))\n",
    "        var = tf.cond(tf.cast(is_training,tf.bool), lambda: tf.nn.moments(inputs,[0])[1], lambda: tf.multiply(tf.ones(inputs.get_shape()[-1]), pop_var))\n",
    "        train_mean = tf.cond(tf.cast(is_training,tf.bool), lambda:tf.assign(pop_mean, pop_mean*decay+mean*(1-decay)),lambda:tf.zeros(1))\n",
    "        train_var = tf.cond(tf.cast(is_training,tf.bool),lambda:tf.assign(pop_var, pop_var*decay+var*(1-decay)),lambda:tf.zeros(1))\n",
    "\n",
    "        with tf.control_dependencies([train_mean, train_var]):\n",
    "            return tf.nn.batch_normalization(inputs, mean, var, beta, scale, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZZqe6faCOH1R"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def partial_conv(pixel, mask,is_training, kernel_size, filter_numbers, stride, batch_n, nonlinearity, trans):\n",
    "\n",
    "    with tf.name_scope(\"part_conv\") as scope:\n",
    "        kernel_h = kernel_size[0]\n",
    "        kernel_w = kernel_size[1]\n",
    "        if trans==True:\n",
    "            kernel_d = filter_numbers\n",
    "            kernel_o = pixel.get_shape().as_list()[3]\n",
    "        elif trans==False:\n",
    "            kernel_d = pixel.get_shape().as_list()[3]\n",
    "            kernel_o = filter_numbers\n",
    "        elif trans==\"same_pad\":\n",
    "            #kernel_d = pixel.get_shape().as_list()[3]\n",
    "            #kernel_o = filter_numbers\n",
    "            kernel_d = filter_numbers\n",
    "            kernel_o = pixel.get_shape().as_list()[3]\n",
    "        elif trans==\"one\":\n",
    "            kernel_d = pixel.get_shape().as_list()[3]\n",
    "            kernel_o = filter_numbers\n",
    "            \n",
    "            \n",
    "        W = tf.get_variable('Weights', (kernel_h, kernel_w, kernel_d, kernel_o),\n",
    "                            initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "        #tf.add_to_collection('weights', W)\n",
    "        print(W.name)\n",
    "        W1 = tf.ones((kernel_h, kernel_w, kernel_d, kernel_o), name='Weights_mask')\n",
    "\n",
    "        Z1 = tf.multiply(pixel, mask, name=\"element_op\")\n",
    "\n",
    "        if trans==True:\n",
    "            #need to fix for variable last batch size. The last mini_batch will be of different size most of the time\n",
    "            out_shape_list = pixel.get_shape().as_list()\n",
    "            out_shape_list[1] = pixel.get_shape().as_list()[1] + 2\n",
    "            out_shape_list[2] = pixel.get_shape().as_list()[2] + 2\n",
    "            out_shape_list[3] = filter_numbers\n",
    "            out_shape = tf.constant(out_shape_list)\n",
    "            #out_shape = tf.TensorShape(out_shape_list)\n",
    "            #out_shape = tf.cast(out_shape,tf.int32)\n",
    "            prime_conv = tf.nn.conv2d_transpose(Z1, W,out_shape, strides=stride, padding=\"VALID\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d_transpose(mask, W1,output_shape=tf.TensorShape(out_shape_list), strides=stride, padding=\"VALID\", name=\"sec_conv\")\n",
    "        elif trans==False:\n",
    "            prime_conv = tf.nn.conv2d(Z1, W, strides=stride, padding=\"VALID\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d(mask, W1, strides=stride, padding=\"VALID\", name=\"sec_conv\")\n",
    "        elif trans==\"same_pad\":\n",
    "            #prime_conv = tf.nn.conv2d(Z1, W, strides=stride, padding=\"SAME\", name=\"prime_conv\")\n",
    "            #sec_conv = tf.nn.conv2d(mask, W1, strides=stride, padding=\"SAME\", name=\"sec_conv\")\n",
    "            out_shape_list = pixel.get_shape().as_list()\n",
    "            out_shape_list[1] = pixel.get_shape().as_list()[1] \n",
    "            out_shape_list[2] = pixel.get_shape().as_list()[2] \n",
    "            out_shape_list[3] = filter_numbers\n",
    "            out_shape = tf.constant(out_shape_list)\n",
    "            prime_conv = tf.nn.conv2d_transpose(Z1, W,out_shape, strides=stride, padding=\"SAME\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d_transpose(mask, W1,output_shape=tf.TensorShape(out_shape_list), strides=stride, padding=\"SAME\", name=\"sec_conv\")\n",
    "        elif trans==\"one\":\n",
    "            prime_conv = tf.nn.conv2d(Z1, W, strides=stride, padding=\"VALID\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d(mask, W1, strides=stride, padding=\"VALID\", name=\"sec_conv\")\n",
    "            \n",
    "\n",
    "        inver_sum = tf.divide(tf.constant(1.0), sec_conv)\n",
    "        clean_sum = tf.where(tf.is_inf(inver_sum), tf.zeros_like(inver_sum), inver_sum)\n",
    "\n",
    "        weighted_pixel = tf.multiply(prime_conv, clean_sum, name=\"multi_inver_sum\")\n",
    "        up_mask = tf.where(tf.not_equal(sec_conv, tf.constant(0.0)),tf.ones_like(sec_conv),sec_conv)\n",
    "\n",
    "        #normalized_out = tf.cond(tf.cast(batch_n,tf.bool), lambda:batch_norm(weighted_pixel, tf.cast(is_training,tf.bool)), lambda:weighted_pixel)\n",
    "        #B = tf.get_variable('Biases',(1,weighted_pixel.get_shape()[1],weighted_pixel.get_shape()[2],weighted_pixel.get_shape()[3]),\n",
    "        #                    initializer=tf.constant_initializer(.01))\n",
    "        B = tf.get_variable('Biases',(1,1,1,prime_conv.get_shape()[3]),\n",
    "                            initializer=tf.constant_initializer(.01))\n",
    "        \n",
    "        normalized_out = tf.add(weighted_pixel,B)\n",
    "        #normalized_out = weighted_pixel\n",
    "        \n",
    "        if nonlinearity==\"relu\":\n",
    "            up_pixel = tf.nn.relu(normalized_out, name=\"relu\")\n",
    "        elif nonlinearity==\"leaky_relu\":\n",
    "            up_pixel = tf.nn.leaky_relu(normalized_out, name=\"leaky_relu\")\n",
    "        elif nonlinearity==\"none\":\n",
    "            #up_pixel = normalized_out\n",
    "            up_pixel = tf.sigmoid(normalized_out)\n",
    "            #up_pixel = tf.nn.relu(normalized_out, name=\"relu\")\n",
    "        elif nonlinearity==\"elu\":\n",
    "            up_pixel = tf.keras.activations.elu(normalized_out)\n",
    "            \n",
    "        tf.summary.histogram(\"weights\", W)    \n",
    "        tf.summary.histogram(\"biases\", B)   \n",
    "        tf.summary.histogram(\"activations\", up_pixel)   \n",
    "        \n",
    "        return up_pixel, up_mask\n",
    "    \n",
    "\n",
    "\n",
    "def place_holders(mini_size,height, width, channels):\n",
    "    #X = tf.placeholder(tf.float32, shape=(mini_size, height, width, channels))\n",
    "    Y = tf.placeholder(tf.float32, shape=(mini_size, height, width, channels))\n",
    "    M = tf.placeholder(tf.float32, shape=(mini_size, height, width, channels))\n",
    "    return M ,Y\n",
    "\n",
    "\n",
    "def near_up_sampling(pixel, mask, output_size):\n",
    "    with tf.name_scope(\"nearest_up\") as scope:\n",
    "        up_pixel = tf.image.resize_nearest_neighbor(pixel, size=output_size, name=\"nearest_pixel_up\")\n",
    "        up_mask = tf.image.resize_nearest_neighbor(pixel, size=output_size, name=\"nearest_mask_up\")\n",
    "        return up_pixel, up_mask\n",
    "\n",
    "def concat(near_pixel, pconv_pixel, near_mask, pconv_mask):\n",
    "    with tf.name_scope(\"concatenation\") as scope:\n",
    "        up_pixel = tf.concat([pconv_pixel, near_pixel], axis=3)\n",
    "        up_mask = tf.concat([pconv_mask,near_mask], axis=3)\n",
    "        return up_pixel, up_mask\n",
    "\n",
    "def decoding_layer(pixel_in,mask_in,is_training, output_size_in, pconv_pixel1, pconv_mask1, filter_numbers1):\n",
    "    with tf.name_scope(\"decoding\") as scope:\n",
    "        near_pixel1,near_mask1 = near_up_sampling(pixel_in,mask_in,output_size_in)\n",
    "        concat_pixel,concat_mask = concat(near_pixel1, pconv_pixel1, near_mask1, pconv_mask1)\n",
    "        pixel_out,mask_out = partial_conv(concat_pixel,concat_mask,is_training,[3,3],filter_numbers1,[1,1,1,1],\n",
    "                                        True,\"leaky_relu\",trans=True)\n",
    "        return pixel_out,mask_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mFUVWDrVOH1V"
   },
   "outputs": [],
   "source": [
    "def forward_prop(is_training, pixel, mask):\n",
    "    non_lin = \"relu\"\n",
    "    \n",
    "#     with tf.variable_scope(\"PConv1\") as scope:\n",
    "#         p_out1,m_out1 = partial_conv(pixel,mask,is_training,kernel_size=[3,3],filter_numbers=64,stride=[1,2,2,1],\n",
    "#                                     batch_n=False,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv2\") as scope:\n",
    "        p_out2,m_out2 = partial_conv(pixel,mask,is_training,kernel_size=[3,3],filter_numbers=64,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=non_lin,trans=False)\n",
    "    with tf.variable_scope(\"PConv3\") as scope:\n",
    "        p_out3,m_out3 = partial_conv(p_out2,m_out2,is_training,kernel_size=[3,3],filter_numbers=128,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=non_lin,trans=False)\n",
    "    with tf.variable_scope(\"PConv4\") as scope:\n",
    "        p_out4,m_out4 = partial_conv(p_out3,m_out3,is_training,kernel_size=[3,3],filter_numbers=256,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=non_lin,trans=False)\n",
    "    with tf.variable_scope(\"PConv5\") as scope:\n",
    "        p_out5,m_out5 = partial_conv(p_out4,m_out4,is_training,kernel_size=[3,3],filter_numbers=256,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=non_lin,trans=False)\n",
    "    with tf.variable_scope(\"PConv6\") as scope:\n",
    "        p_out6,m_out6 = partial_conv(p_out5,m_out5,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=non_lin,trans=False)\n",
    "    with tf.variable_scope(\"PConv7\") as scope:\n",
    "        p_out7,m_out7 = partial_conv(p_out6,m_out6,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=non_lin,trans=False)\n",
    "    with tf.variable_scope(\"PConv8\") as scope:\n",
    "        p_out8,m_out8 = partial_conv(p_out7,m_out7,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,1,1,1],\n",
    "                                    batch_n=True,nonlinearity=non_lin,trans=False)\n",
    "    with tf.variable_scope(\"decoding9\") as scope:\n",
    "        p_out9,m_out9 = decoding_layer(p_out8,m_out8,is_training,(p_out7.get_shape().as_list()[1],p_out7.get_shape().as_list()[2]),\n",
    "                                        p_out7,m_out7,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding10\") as scope:\n",
    "        p_out10,m_out10 = decoding_layer(p_out9,m_out9,is_training,(p_out6.get_shape().as_list()[1],p_out6.get_shape().as_list()[2]),\n",
    "                                        p_out6,m_out6,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding11\") as scope:\n",
    "        p_out11,m_out11 = decoding_layer(p_out10,m_out10,is_training,(p_out5.get_shape().as_list()[1],p_out5.get_shape().as_list()[2]),\n",
    "                                        p_out5,m_out5,filter_numbers1=256)\n",
    "\n",
    "    with tf.variable_scope(\"decoding12\") as scope:\n",
    "        p_out12,m_out12 = decoding_layer(p_out11,m_out11,is_training,(p_out4.get_shape().as_list()[1],p_out4.get_shape().as_list()[2]),\n",
    "                                        p_out4,m_out4,filter_numbers1=256)\n",
    "\n",
    "    with tf.variable_scope(\"decoding13\") as scope:\n",
    "        p_out13,m_out13 = decoding_layer(p_out12,m_out12,is_training,(p_out3.get_shape().as_list()[1],p_out3.get_shape().as_list()[2]),\n",
    "                                        p_out3,m_out3,filter_numbers1=128)\n",
    "\n",
    "    with tf.variable_scope(\"decoding14\") as scope:\n",
    "        p_out14,m_out14 = decoding_layer(p_out13,m_out13,is_training,(p_out2.get_shape().as_list()[1],p_out2.get_shape().as_list()[2]),\n",
    "                                        p_out2,m_out2,filter_numbers1=64)\n",
    "\n",
    "#     with tf.variable_scope(\"decoding15\") as scope:\n",
    "#         p_out15,m_out15 = decoding_layer(p_out14,m_out14,is_training,(p_out1.get_shape().as_list()[1],p_out1.get_shape().as_list()[2]),\n",
    "#                                         p_out1,m_out1,filter_numbers1=64)\n",
    "\n",
    "    #with tf.variable_scope(\"decoding16\") as scope:\n",
    "    #    p_out16,m_out16 = decoding_layer(p_out15,m_out15,is_training,(pixel.get_shape().as_list()[1],pixel.get_shape().as_list()[2]),\n",
    "    #                                    pixel,mask,filter_numbers1=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(\"decoding15\") as scope:\n",
    "        near_pixel1,near_mask1 = near_up_sampling(p_out14,m_out14,(pixel.get_shape().as_list()[1],pixel.get_shape().as_list()[2]))\n",
    "        pixel_hole = tf.multiply(pixel, mask, name=\"multiply_mask\")\n",
    "        concat_pixel,concat_mask = concat(near_pixel1, pixel_hole, near_mask1, mask)\n",
    "        pixel_out,mask_out = partial_conv(concat_pixel,concat_mask,is_training,[1,1],filter_numbers=1,stride=[1,1,1,1],\n",
    "                                        batch_n=False,nonlinearity=\"none\",trans=\"one\")\n",
    "    \n",
    "    return pixel_out,mask_out\n",
    "\n",
    "\n",
    "\n",
    "def compute_cost(pixel_gt,mask_gt,pixel_pre,hole_pera,valid_pera):\n",
    "    with tf.name_scope(\"cost\") as scope:\n",
    "        loss_valid = tf.losses.absolute_difference(tf.multiply(pixel_gt,mask_gt),tf.multiply(pixel_pre,mask_gt), weights=1.0,\n",
    "                                                   reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)\n",
    "        loss_hole = tf.losses.absolute_difference(tf.multiply(pixel_gt,(1-mask_gt)),tf.multiply(pixel_pre,(1-mask_gt)), weights=1.0,\n",
    "                                                    reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)\n",
    "        \n",
    "        #loss_hole = loss_hole * loss_hole\n",
    "        #loss_valid = loss_valid * loss_valid \n",
    "        #loss_valid = tf.losses.mean_squared_error(tf.multiply(pixel_gt,mask_gt),tf.multiply(pixel_pre,mask_gt))\n",
    "        #loss_hole = tf.losses.mean_squared_error(tf.multiply(pixel_gt,(1-mask_gt)),tf.multiply(pixel_pre,(1-mask_gt)))\n",
    "\n",
    "        #total_loss = (tf.multiply(valid_pera,loss_valid) + tf.multiply(hole_pera,loss_hole))/(hole_pera+valid_pera)\n",
    "        #total_loss = (loss_valid + tf.multiply(hole_pera,loss_hole))/(hole_pera)\n",
    "        total_loss = (valid_pera*loss_valid + hole_pera*loss_hole)/(hole_pera+valid_pera)\n",
    "\n",
    "        tf.summary.scalar('loss',total_loss)\n",
    "   \n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lgvAO8mGOH1d"
   },
   "outputs": [],
   "source": [
    "def model(learning_rate,num_epochs,mini_size,break_t,break_v,pt_out,hole_pera,valid_pera):\n",
    "    #ops.reset_default_graph()\n",
    "    tf.summary.scalar('learning_rate',learning_rate)\n",
    "    tf.summary.scalar('batch_size',mini_size)\n",
    "    tf.summary.scalar('training_break',break_t)\n",
    "    tf.summary.scalar('validation_break',break_v)\n",
    "    tf.summary.scalar('print_interval',pt_out)\n",
    "    tf.summary.scalar('hole_loss_weight',hole_pera)\n",
    "    tf.summary.scalar('valid_loss_weight',valid_pera)\n",
    "  \n",
    "    m = 19488\n",
    "    #m = 8\n",
    "    #h = 512\n",
    "    #w = 512\n",
    "    #c = 1\n",
    "    \n",
    "    m_val_size = 1888\n",
    "        \n",
    "    #filenames = \"/media/antor/Files/ML/Papers/train_mfix.tfrecords\"\n",
    "    filenames = tf.placeholder(tf.string)\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.shuffle(200)\n",
    "    dataset = dataset.batch(mini_size)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    " \n",
    "    pix_gt, mask_in = iterator.get_next()\n",
    "    \n",
    "    pix_gt = tf.reshape(pix_gt,[mini_size,256,256,1])\n",
    "    mask_in = tf.reshape(mask_in,[mini_size,256,256,1])\n",
    "    \n",
    "    tf.summary.image(\"input_Y\",pix_gt,3)\n",
    "    tf.summary.image(\"input_M\",mask_in,3)\n",
    "    \n",
    "    pixel_out, mask_out = forward_prop(is_training=is_training,pixel=pix_gt, mask=mask_in)\n",
    "    \n",
    "    tf.summary.image(\"output_Y\",pixel_out,3)\n",
    "    tf.summary.image(\"output_M\",mask_out,3)\n",
    "    \n",
    "    cost = compute_cost(pixel_gt=pix_gt, mask_gt=mask_in, pixel_pre=pixel_out, hole_pera=hole_pera,valid_pera=valid_pera)\n",
    "    #tf.add_to_collection('cst', cost)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    #tf.add_to_collection('opt', optimizer)\n",
    "    \n",
    "    num_mini = int(m/mini_size)          #must keep this fully divided and num_mini output as int pretty sure it doesn't need\n",
    "                                    #to be an int    \n",
    "    merge_sum = tf.summary.merge_all()\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())   #for tensorboard\n",
    "    \n",
    "    saver = tf.train.Saver()    #for model saving\n",
    "    #builder = tf.saved_model.builder.SavedModelBuilder('./SavedModel/')\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    \n",
    "    sess.run(init)\n",
    "    sess.run(iterator.initializer,feed_dict={filenames:\"/media/antor/Files/ML/Papers/train_last.tfrecords\"})\n",
    "    \n",
    "    mini_cost = 0.0\n",
    "    counter = 1\n",
    "    epoch_cost = 0.0\n",
    "    epoch = 0\n",
    "    \n",
    "    now_m = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")    #for tensorboard\n",
    "    root_logdir_m = \"tf_models\"\n",
    "    logdir_m = \"{}/run-{}/\".format(root_logdir_m, now_m)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            \n",
    "            _ , temp_cost = sess.run([optimizer,cost], feed_dict={is_training:True})\n",
    "                       \n",
    "            #mini_cost += temp_cost/num_mini\n",
    "            mini_cost += temp_cost/pt_out\n",
    "            epoch_cost += temp_cost/num_mini\n",
    "            \n",
    "            if counter%20 == 0:\n",
    "                s = sess.run(merge_sum)\n",
    "                file_writer.add_summary(s,counter)\n",
    "                            \n",
    "            if counter%num_mini==0:\n",
    "                print(\"cost after epoch \" + str(counter/num_mini) + \": \" + str(epoch_cost))\n",
    "                epoch_cost =0.0 \n",
    "                epoch+=1\n",
    "                \n",
    "            #print(\"cost after epoch \" + str(counter/num_mini) + \": \" + str(mini_cost))\n",
    "            \n",
    "            #if counter%1==0:\n",
    "            #    print(\"mini batch cost of batch \" + str(counter) + \" is : \" + str(temp_cost))\n",
    "            \n",
    "            if counter%pt_out==0:\n",
    "                print(\"mini batch cost of batch \" + str(counter) + \" is : \" + str(mini_cost))\n",
    "                mini_cost =0.0 \n",
    "                #gc.collect()\n",
    "                \n",
    "            if counter*mini_size>=break_t:\n",
    "                #saver.save(sess,logdir_m+\"my_model\",global_step=counter)\n",
    "                break\n",
    "            \n",
    "            if epoch ==  num_epochs:\n",
    "                break\n",
    "            \n",
    "            counter = counter + 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    \n",
    "               #for tensorboard\n",
    "    \n",
    "    num_mini_val = int(m_val_size/mini_size)\n",
    "\n",
    "    counter_val = 1\n",
    "\n",
    "    sess.run(iterator.initializer,feed_dict={filenames:\"/media/antor/Files/ML/Papers/val_last.tfrecords\"})\n",
    "    #sess.run(iterator_val.initializer,feed_dict={filenames_val:\"/media/antor/Files/ML/Papers/val_mfix.tfrecords\"})\n",
    "\n",
    "    mini_cost_val = 0.0\n",
    "    epoch_cost_val = 0.0\n",
    "    mini_br = int(break_v/mini_size)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            \n",
    "            #temp_cost_val = sess.run(cost, feed_dict={M:mask_in_val,Y:label_in_val,is_training:False})\n",
    "            temp_cost_val = sess.run(cost, feed_dict={is_training:False})\n",
    "            #temp_cost_val = sess.run(cost_val)\n",
    "\n",
    "            epoch_cost_val += temp_cost_val/num_mini_val\n",
    "            mini_cost_val +=  temp_cost_val/mini_br\n",
    "            \n",
    "            if counter_val%num_mini_val==0:\n",
    "                print(\"cost after epoch : \" + str(epoch_cost_val))\n",
    "                s = sess.run(merge_sum)\n",
    "                file_writer.add_summary(s,counter_val)\n",
    "                #epoch_cost_val =0.0 \n",
    "            \n",
    "            if counter_val*mini_size>=break_v:\n",
    "                print(\"cost of val set : \" + str(mini_cost_val))\n",
    "                s = sess.run(merge_sum)\n",
    "                file_writer.add_summary(s,counter_val)\n",
    "                break\n",
    "            \n",
    "            \n",
    "            counter_val = counter_val + 1          \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    file_writer.close()    \n",
    "    now_m = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")    #for tensorboard\n",
    "    root_logdir_m = \"tf_models\"\n",
    "    logdir_m = \"{}/run-{}/\".format(root_logdir_m, now_m)\n",
    "#     tf.saved_model.simple_save(session=sess,export_dir=logdir_m,inputs={\"x\":pix_gt,\"y\":mask_in},outputs={\"z\":pixel_out})\n",
    "    saver.save(sess,logdir_m+\"my_model_fin\")\n",
    "#     builder.add_meta_graph_and_variables(sess,\n",
    "#                                        [tf.saved_model.tag_constants.TRAINING],\n",
    "#                                        signature_def_map=None,\n",
    "#                                        assets_collection=None)\n",
    "#     builder.save() \n",
    "    sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from tensorflow.python.framework import ops\\n\\nf = np.random.uniform(-5,0,6)\\ni = 10**f\\n#print(f)\\nprint(i)\\nb = [2,4,8,16]\\nfor j in i:\\n    for k in b:\\n        print(j,k)\\n        model(learning_rate=j,num_epochs=1,mini_size=k,break_t=1500,break_v=150,pt_out=20,hole_pera=6.0,valid_pera=1.0)\\n        ops.reset_default_graph() '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from tensorflow.python.framework import ops\n",
    "\n",
    "f = np.random.uniform(-5,0,6)\n",
    "i = 10**f\n",
    "#print(f)\n",
    "print(i)\n",
    "b = [2,4,8,16]\n",
    "for j in i:\n",
    "    for k in b:\n",
    "        print(j,k)\n",
    "        model(learning_rate=j,num_epochs=1,mini_size=k,break_t=1500,break_v=150,pt_out=20,hole_pera=6.0,valid_pera=1.0)\n",
    "        ops.reset_default_graph() '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#i=.05\\nfrom tensorflow.python.framework import ops\\n#import random\\nh = np.random.randint(3,9,size=10)\\nv = np.random.randint(1,20,size=15)\\n#random.shuffle(h)\\n#random.shuffle(v)\\n\\n#f = np.random.uniform(np.log10(.0094958),np.log10(.009907),7)\\nf = np.random.uniform(.0094958,.009907,7)\\ni = 10**f\\n#i= [.07,.01,.007,.099999,.001]\\n#i = np.random.uniform(.01039,.04,5)\\nprint(i)\\nprint(f)\\n\\nfor k in f:\\n    \\n    print(k)\\n    model(learning_rate=k,num_epochs=1,mini_size=16,break_t=8000,break_v=100,pt_out=20,hole_pera=6.0,valid_pera=1.0)\\n    ops.reset_default_graph() '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#i=.05\n",
    "from tensorflow.python.framework import ops\n",
    "#import random\n",
    "h = np.random.randint(3,9,size=10)\n",
    "v = np.random.randint(1,20,size=15)\n",
    "#random.shuffle(h)\n",
    "#random.shuffle(v)\n",
    "\n",
    "#f = np.random.uniform(np.log10(.0094958),np.log10(.009907),7)\n",
    "f = np.random.uniform(.0094958,.009907,7)\n",
    "i = 10**f\n",
    "#i= [.07,.01,.007,.099999,.001]\n",
    "#i = np.random.uniform(.01039,.04,5)\n",
    "print(i)\n",
    "print(f)\n",
    "\n",
    "for k in f:\n",
    "    \n",
    "    print(k)\n",
    "    model(learning_rate=k,num_epochs=1,mini_size=16,break_t=8000,break_v=100,pt_out=20,hole_pera=6.0,valid_pera=1.0)\n",
    "    ops.reset_default_graph() '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "i5w7yUdWOH1h",
    "outputId": "a3dd9e34-f947-4e9c-be22-f5437697dd5f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PConv2/Weights:0\n",
      "PConv3/Weights:0\n",
      "PConv4/Weights:0\n",
      "PConv5/Weights:0\n",
      "PConv6/Weights:0\n",
      "PConv7/Weights:0\n",
      "PConv8/Weights:0\n",
      "decoding9/Weights:0\n",
      "decoding10/Weights:0\n",
      "decoding11/Weights:0\n",
      "decoding12/Weights:0\n",
      "decoding13/Weights:0\n",
      "decoding14/Weights:0\n",
      "decoding15/Weights:0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7649356029b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.00960955\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmini_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbreak_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbreak_v\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpt_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhole_pera\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_pera\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-a48477bae540>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(learning_rate, num_epochs, mini_size, break_t, break_v, pt_out, hole_pera, valid_pera)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtemp_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;31m#mini_cost += temp_cost/num_mini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model(learning_rate=.00960955,num_epochs=1,mini_size=16,break_t=5000,break_v=200,pt_out=20,hole_pera=6.0,valid_pera=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "I82s6e35OH1t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "landsat_image _inpaintingerere.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
