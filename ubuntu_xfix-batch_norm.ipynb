{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "K0JU1wEzOH07",
    "outputId": "ec3065cd-da37-40ce-8763-cda85a3a6cf8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import gc\n",
    "#import cv2\n",
    "#import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")    #for tensorboard\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "agRyZL61OH1P"
   },
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    \n",
    "        \n",
    "        \n",
    "    features = {\n",
    "                \"image_y\": tf.FixedLenFeature((), tf.string ),\n",
    "                \"image_m\": tf.FixedLenFeature((), tf.string )\n",
    "                #\"image_x\": tf.FixedLenFeature((), tf.string )\n",
    "                }\n",
    "\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "\n",
    "    image_y = tf.decode_raw(parsed_features[\"image_y\"],  tf.float64)\n",
    "    image_m = tf.decode_raw(parsed_features[\"image_m\"],  tf.float64)\n",
    "\n",
    "    image_y = tf.reshape(image_y, [512,512,1])\n",
    "    image_m = tf.reshape(image_m, [512,512,1])\n",
    "    #image_x = tf.decode_raw(parsed_features[\"image_x\"],  tf.float64)\n",
    "    #tf.summary.image(\"64_Y\",image_y,3)\n",
    "    #tf.summary.image(\"64_M\",image_m,3)\n",
    "\n",
    "    image_y = tf.cast(image_y,dtype=tf.float32)\n",
    "    image_m = tf.cast(image_m,dtype=tf.float32)\n",
    "    #image_x = tf.cast(image_x,dtype=tf.float32)\n",
    "    #tf.summary.image(\"32_Y\",image_y,3)\n",
    "    #tf.summary.image(\"32_M\",image_m,3)\n",
    "\n",
    "    #image_y = tf.reshape(image_y, [512,512,1])\n",
    "    #image_m = tf.reshape(image_m, [512,512,1])\n",
    "    #image_x = tf.reshape(image_x, [512,512,1])\n",
    "\n",
    "    return image_y,image_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(inputs, is_training, decay=.5, epsilon=0.00000001):\n",
    "    with tf.name_scope(\"batch_norm\") as scope:\n",
    "\n",
    "\n",
    "        scale = tf.get_variable(\"scale_BN\", (inputs.get_shape()[1:4]), initializer=tf.ones_initializer())\n",
    "        beta = tf.get_variable(\"beta_BN\", (inputs.get_shape()[1:4]), initializer=tf.zeros_initializer())\n",
    "        pop_mean = tf.get_variable(\"pop_mean\", (inputs.get_shape()[1:4]), initializer=tf.zeros_initializer(), trainable=False)\n",
    "        pop_var = tf.get_variable(\"pop_var\", (inputs.get_shape()[1:4]), initializer=tf.ones_initializer(), trainable=False)\n",
    "\n",
    "        mean = tf.cond(tf.cast(is_training,tf.bool), lambda: tf.nn.moments(inputs,[0])[0], lambda: tf.multiply(tf.ones(inputs.get_shape()[1:4]), pop_mean))\n",
    "        var = tf.cond(tf.cast(is_training,tf.bool), lambda: tf.nn.moments(inputs,[0])[1], lambda: tf.multiply(tf.ones(inputs.get_shape()[-1]), pop_var))\n",
    "        train_mean = tf.cond(tf.cast(is_training,tf.bool), lambda:tf.assign(pop_mean, pop_mean*decay+mean*(1-decay)),lambda:tf.zeros(1))\n",
    "        train_var = tf.cond(tf.cast(is_training,tf.bool),lambda:tf.assign(pop_var, pop_var*decay+var*(1-decay)),lambda:tf.zeros(1))\n",
    "\n",
    "        with tf.control_dependencies([train_mean, train_var]):\n",
    "            return tf.nn.batch_normalization(inputs, mean, var, beta, scale, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZZqe6faCOH1R"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def partial_conv(pixel, mask,is_training, kernel_size, filter_numbers, stride, batch_n, nonlinearity, trans):\n",
    "\n",
    "    with tf.name_scope(\"part_conv\") as scope:\n",
    "        kernel_h = kernel_size[0]\n",
    "        kernel_w = kernel_size[1]\n",
    "        if trans==True:\n",
    "            kernel_d = filter_numbers\n",
    "            kernel_o = pixel.get_shape().as_list()[3]\n",
    "        elif trans==False:\n",
    "            kernel_d = pixel.get_shape().as_list()[3]\n",
    "            kernel_o = filter_numbers\n",
    "        elif trans==\"same_pad\":\n",
    "            #kernel_d = pixel.get_shape().as_list()[3]\n",
    "            #kernel_o = filter_numbers\n",
    "            kernel_d = filter_numbers\n",
    "            kernel_o = pixel.get_shape().as_list()[3]\n",
    "        elif trans==\"one\":\n",
    "            kernel_d = pixel.get_shape().as_list()[3]\n",
    "            kernel_o = filter_numbers\n",
    "            \n",
    "            \n",
    "        W = tf.get_variable('Weights', (kernel_h, kernel_w, kernel_d, kernel_o),\n",
    "                            initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "        \n",
    "        \n",
    "        W1 = tf.ones((kernel_h, kernel_w, kernel_d, kernel_o), name='Weights_mask')\n",
    "\n",
    "        Z1 = tf.multiply(pixel, mask, name=\"element_op\")\n",
    "\n",
    "        if trans==True:\n",
    "            #need to fix for variable last batch size. The last mini_batch will be of different size most of the time\n",
    "            out_shape_list = pixel.get_shape().as_list()\n",
    "            out_shape_list[1] = pixel.get_shape().as_list()[1] + 2\n",
    "            out_shape_list[2] = pixel.get_shape().as_list()[2] + 2\n",
    "            out_shape_list[3] = filter_numbers\n",
    "            out_shape = tf.constant(out_shape_list)\n",
    "            #out_shape = tf.TensorShape(out_shape_list)\n",
    "            #out_shape = tf.cast(out_shape,tf.int32)\n",
    "            prime_conv = tf.nn.conv2d_transpose(Z1, W,out_shape, strides=stride, padding=\"VALID\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d_transpose(mask, W1,output_shape=tf.TensorShape(out_shape_list), strides=stride, padding=\"VALID\", name=\"sec_conv\")\n",
    "        elif trans==False:\n",
    "            prime_conv = tf.nn.conv2d(Z1, W, strides=stride, padding=\"VALID\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d(mask, W1, strides=stride, padding=\"VALID\", name=\"sec_conv\")\n",
    "        elif trans==\"same_pad\":\n",
    "            #prime_conv = tf.nn.conv2d(Z1, W, strides=stride, padding=\"SAME\", name=\"prime_conv\")\n",
    "            #sec_conv = tf.nn.conv2d(mask, W1, strides=stride, padding=\"SAME\", name=\"sec_conv\")\n",
    "            out_shape_list = pixel.get_shape().as_list()\n",
    "            out_shape_list[1] = pixel.get_shape().as_list()[1] \n",
    "            out_shape_list[2] = pixel.get_shape().as_list()[2] \n",
    "            out_shape_list[3] = filter_numbers\n",
    "            out_shape = tf.constant(out_shape_list)\n",
    "            prime_conv = tf.nn.conv2d_transpose(Z1, W,out_shape, strides=stride, padding=\"SAME\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d_transpose(mask, W1,output_shape=tf.TensorShape(out_shape_list), strides=stride, padding=\"SAME\", name=\"sec_conv\")\n",
    "        elif trans==\"one\":\n",
    "            prime_conv = tf.nn.conv2d(Z1, W, strides=stride, padding=\"SAME\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d(mask, W1, strides=stride, padding=\"SAME\", name=\"sec_conv\")\n",
    "            \n",
    "\n",
    "        inver_sum = tf.divide(tf.constant(1.0), sec_conv)\n",
    "        clean_sum = tf.where(tf.is_inf(inver_sum), tf.zeros_like(inver_sum), inver_sum)\n",
    "\n",
    "        weighted_pixel = tf.multiply(prime_conv, clean_sum, name=\"multi_inver_sum\")\n",
    "        up_mask = tf.where(tf.not_equal(sec_conv, tf.constant(0.0)),tf.ones_like(sec_conv),sec_conv)\n",
    "\n",
    "        #normalized_out = tf.cond(tf.cast(batch_n,tf.bool), lambda:batch_norm(weighted_pixel, tf.cast(is_training,tf.bool)), lambda:weighted_pixel)\n",
    "        B = tf.get_variable('Biases',(1,weighted_pixel.get_shape()[1],weighted_pixel.get_shape()[2],weighted_pixel.get_shape()[3]),\n",
    "                            initializer=tf.constant_initializer(.01))\n",
    "        \n",
    "        normalized_out = tf.add(weighted_pixel,B)\n",
    "        #normalized_out = weighted_pixel\n",
    "        \n",
    "        if nonlinearity==\"relu\":\n",
    "            up_pixel = tf.nn.relu(normalized_out, name=\"relu\")\n",
    "        elif nonlinearity==\"leaky_relu\":\n",
    "            up_pixel = tf.nn.leaky_relu(normalized_out, name=\"leaky_relu\")\n",
    "        elif nonlinearity==\"none\":\n",
    "            #up_pixel = normalized_out\n",
    "            up_pixel = tf.sigmoid(normalized_out)\n",
    "            #up_pixel = tf.nn.relu(normalized_out, name=\"relu\")\n",
    "            \n",
    "        tf.summary.histogram(\"weights\", W)    \n",
    "        tf.summary.histogram(\"biases\", B)   \n",
    "        tf.summary.histogram(\"activations\", up_pixel)   \n",
    "        \n",
    "        return up_pixel, up_mask\n",
    "    \n",
    "\n",
    "\n",
    "def place_holders(mini_size,height, width, channels):\n",
    "    #X = tf.placeholder(tf.float32, shape=(mini_size, height, width, channels))\n",
    "    Y = tf.placeholder(tf.float32, shape=(mini_size, height, width, channels))\n",
    "    M = tf.placeholder(tf.float32, shape=(mini_size, height, width, channels))\n",
    "    return M ,Y\n",
    "\n",
    "\n",
    "def near_up_sampling(pixel, mask, output_size):\n",
    "    with tf.name_scope(\"nearest_up\") as scope:\n",
    "        up_pixel = tf.image.resize_nearest_neighbor(pixel, size=output_size, name=\"nearest_pixel_up\")\n",
    "        up_mask = tf.image.resize_nearest_neighbor(pixel, size=output_size, name=\"nearest_mask_up\")\n",
    "        return up_pixel, up_mask\n",
    "\n",
    "def concat(near_pixel, pconv_pixel, near_mask, pconv_mask):\n",
    "    with tf.name_scope(\"concatenation\") as scope:\n",
    "        up_pixel = tf.concat([pconv_pixel, near_pixel], axis=3)\n",
    "        up_mask = tf.concat([pconv_mask,near_mask], axis=3)\n",
    "        return up_pixel, up_mask\n",
    "\n",
    "def decoding_layer(pixel_in,mask_in,is_training, output_size_in, pconv_pixel1, pconv_mask1, filter_numbers1):\n",
    "    with tf.name_scope(\"decoding\") as scope:\n",
    "        near_pixel1,near_mask1 = near_up_sampling(pixel_in,mask_in,output_size_in)\n",
    "        concat_pixel,concat_mask = concat(near_pixel1, pconv_pixel1, near_mask1, pconv_mask1)\n",
    "        pixel_out,mask_out = partial_conv(concat_pixel,concat_mask,is_training,[3,3],filter_numbers1,[1,1,1,1],\n",
    "                                        True,\"leaky_relu\",trans=True)\n",
    "        return pixel_out,mask_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mFUVWDrVOH1V"
   },
   "outputs": [],
   "source": [
    "def forward_prop(is_training, pixel, mask):\n",
    "\n",
    "    with tf.variable_scope(\"PConv1\") as scope:\n",
    "        p_out1,m_out1 = partial_conv(pixel,mask,is_training,kernel_size=[7,7],filter_numbers=64,stride=[1,2,2,1],\n",
    "                                    batch_n=False,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv2\") as scope:\n",
    "        p_out2,m_out2 = partial_conv(p_out1,m_out1,is_training,kernel_size=[5,5],filter_numbers=128,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv3\") as scope:\n",
    "        p_out3,m_out3 = partial_conv(p_out2,m_out2,is_training,kernel_size=[5,5],filter_numbers=256,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv4\") as scope:\n",
    "        p_out4,m_out4 = partial_conv(p_out3,m_out3,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv5\") as scope:\n",
    "        p_out5,m_out5 = partial_conv(p_out4,m_out4,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv6\") as scope:\n",
    "        p_out6,m_out6 = partial_conv(p_out5,m_out5,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv7\") as scope:\n",
    "        p_out7,m_out7 = partial_conv(p_out6,m_out6,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,1,1,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv8\") as scope:\n",
    "        p_out8,m_out8 = partial_conv(p_out7,m_out7,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,1,1,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"decoding9\") as scope:\n",
    "        p_out9,m_out9 = decoding_layer(p_out8,m_out8,is_training,(p_out7.get_shape().as_list()[1],p_out7.get_shape().as_list()[2]),\n",
    "                                        p_out7,m_out7,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding10\") as scope:\n",
    "        p_out10,m_out10 = decoding_layer(p_out9,m_out9,is_training,(p_out6.get_shape().as_list()[1],p_out6.get_shape().as_list()[2]),\n",
    "                                        p_out6,m_out6,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding11\") as scope:\n",
    "        p_out11,m_out11 = decoding_layer(p_out10,m_out10,is_training,(p_out5.get_shape().as_list()[1],p_out5.get_shape().as_list()[2]),\n",
    "                                        p_out5,m_out5,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding12\") as scope:\n",
    "        p_out12,m_out12 = decoding_layer(p_out11,m_out11,is_training,(p_out4.get_shape().as_list()[1],p_out4.get_shape().as_list()[2]),\n",
    "                                        p_out4,m_out4,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding13\") as scope:\n",
    "        p_out13,m_out13 = decoding_layer(p_out12,m_out12,is_training,(p_out3.get_shape().as_list()[1],p_out3.get_shape().as_list()[2]),\n",
    "                                        p_out3,m_out3,filter_numbers1=256)\n",
    "\n",
    "    with tf.variable_scope(\"decoding14\") as scope:\n",
    "        p_out14,m_out14 = decoding_layer(p_out13,m_out13,is_training,(p_out2.get_shape().as_list()[1],p_out2.get_shape().as_list()[2]),\n",
    "                                        p_out2,m_out2,filter_numbers1=128)\n",
    "\n",
    "    with tf.variable_scope(\"decoding15\") as scope:\n",
    "        p_out15,m_out15 = decoding_layer(p_out14,m_out14,is_training,(p_out1.get_shape().as_list()[1],p_out1.get_shape().as_list()[2]),\n",
    "                                        p_out1,m_out1,filter_numbers1=64)\n",
    "\n",
    "    #with tf.variable_scope(\"decoding16\") as scope:\n",
    "    #    p_out16,m_out16 = decoding_layer(p_out15,m_out15,is_training,(pixel.get_shape().as_list()[1],pixel.get_shape().as_list()[2]),\n",
    "    #                                    pixel,mask,filter_numbers1=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(\"decoding16\") as scope:\n",
    "        near_pixel1,near_mask1 = near_up_sampling(p_out15,m_out15,(pixel.get_shape().as_list()[1],pixel.get_shape().as_list()[2]))\n",
    "        pixel_hole = tf.multiply(pixel, mask, name=\"multiply_mask\")\n",
    "        concat_pixel,concat_mask = concat(near_pixel1, pixel_hole, near_mask1, mask)\n",
    "        pixel_out,mask_out = partial_conv(concat_pixel,concat_mask,is_training,[3,3],filter_numbers=1,stride=[1,1,1,1],\n",
    "                                        batch_n=False,nonlinearity=\"none\",trans=\"same_pad\")\n",
    "    \n",
    "    return pixel_out,mask_out\n",
    "\n",
    "\n",
    "\n",
    "def compute_cost(pixel_gt,mask_gt,pixel_pre,hole_pera,valid_pera):\n",
    "    with tf.name_scope(\"cost\") as scope:\n",
    "        loss_valid = tf.losses.absolute_difference(tf.multiply(pixel_gt,mask_gt),tf.multiply(pixel_pre,mask_gt), weights=1.0,\n",
    "                                                    reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)\n",
    "        loss_hole = tf.losses.absolute_difference(tf.multiply(pixel_gt,(1-mask_gt)),tf.multiply(pixel_pre,(1-mask_gt)), weights=1.0,\n",
    "                                                    reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)\n",
    "\n",
    "        #total_loss = (tf.multiply(valid_pera,loss_valid) + tf.multiply(hole_pera,loss_hole))/(hole_pera+valid_pera)\n",
    "        #total_loss = (loss_valid + tf.multiply(hole_pera,loss_hole))/(hole_pera)\n",
    "        total_loss = (valid_pera*loss_valid + hole_pera*loss_hole)/(hole_pera+valid_pera)\n",
    "\n",
    "        tf.summary.scalar('loss',total_loss)\n",
    "   \n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lgvAO8mGOH1d"
   },
   "outputs": [],
   "source": [
    "def model(learning_rate,num_epochs,mini_size,break_t,break_v,pt_out,hole_pera,valid_pera):\n",
    "    #ops.reset_default_graph()\n",
    "    tf.summary.scalar('learning_rate',learning_rate)\n",
    "    tf.summary.scalar('batch_size',mini_size)\n",
    "    tf.summary.scalar('training_break',break_t)\n",
    "    tf.summary.scalar('validation_break',break_v)\n",
    "    tf.summary.scalar('print_interval',pt_out)\n",
    "    tf.summary.scalar('hole_loss_weight',hole_pera)\n",
    "    tf.summary.scalar('valid_loss_weight',valid_pera)\n",
    "  \n",
    "    m = 9882\n",
    "    #m = 8\n",
    "    h = 512\n",
    "    w = 512\n",
    "    c = 1\n",
    "    \n",
    "    m_val_size = 1098\n",
    "        \n",
    "    #filenames = \"/media/antor/Files/ML/Papers/train_mfix.tfrecords\"\n",
    "    filenames = tf.placeholder(tf.string)\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.shuffle(15)\n",
    "    dataset = dataset.batch(mini_size)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    " \n",
    "    pix_gt, mask_in = iterator.get_next()\n",
    "    \n",
    "    pix_gt = tf.reshape(pix_gt,[mini_size,512,512,1])\n",
    "    mask_in = tf.reshape(mask_in,[mini_size,512,512,1])\n",
    "    \n",
    "    tf.summary.image(\"input_Y\",pix_gt,3)\n",
    "    tf.summary.image(\"input_M\",mask_in,3)\n",
    "    \n",
    "    pixel_out, mask_out = forward_prop(is_training=is_training,pixel=pix_gt, mask=mask_in)\n",
    "    \n",
    "    tf.summary.image(\"output_Y\",pixel_out,3)\n",
    "    tf.summary.image(\"output_M\",mask_out,3)\n",
    "    \n",
    "    cost = compute_cost(pixel_gt=pix_gt, mask_gt=mask_in, pixel_pre=pixel_out, hole_pera=hole_pera,valid_pera=valid_pera)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    num_mini = int(m/mini_size)          #must keep this fully divided and num_mini output as int pretty sure it doesn't need\n",
    "                                    #to be an int    \n",
    "    merge_sum = tf.summary.merge_all()\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())   #for tensorboard\n",
    "    \n",
    "    #saver = tf.train.Saver()    #for model saving\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    \n",
    "    sess.run(init)\n",
    "    sess.run(iterator.initializer,feed_dict={filenames:\"/media/antor/Files/ML/Papers/train_mfix.tfrecords\"})\n",
    "    \n",
    "    mini_cost = 0.0\n",
    "    counter = 1\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            _ , temp_cost = sess.run([optimizer,cost], feed_dict={is_training:True})\n",
    "                       \n",
    "            #mini_cost += temp_cost/num_mini\n",
    "            mini_cost += temp_cost/pt_out\n",
    "            \n",
    "            if counter%5 == 0:\n",
    "                s = sess.run(merge_sum)\n",
    "                file_writer.add_summary(s,counter)\n",
    "                            \n",
    "#             if counter%num_mini==0:\n",
    "#                 print(\"cost after epoch \" + str(counter/num_mini) + \": \" + str(mini_cost))\n",
    "#                 mini_cost =0.0 \n",
    "                \n",
    "            #print(\"cost after epoch \" + str(counter/num_mini) + \": \" + str(mini_cost))\n",
    "            \n",
    "            #if counter%1==0:\n",
    "            #    print(\"mini batch cost of batch \" + str(counter) + \" is : \" + str(temp_cost))\n",
    "            \n",
    "            if counter%pt_out==0:\n",
    "                print(\"mini batch cost of batch \" + str(counter) + \" is : \" + str(mini_cost))\n",
    "                mini_cost =0.0 \n",
    "                #gc.collect()\n",
    "                \n",
    "            if counter==break_t:\n",
    "                break\n",
    "            \n",
    "            counter = counter + 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    \n",
    "    file_writer.close()            #for tensorboard\n",
    "    \n",
    "    num_mini_val = int(m_val_size/mini_size)\n",
    "\n",
    "    counter_val = 1\n",
    "\n",
    "    sess.run(iterator.initializer,feed_dict={filenames:\"/media/antor/Files/ML/Papers/val_mfix.tfrecords\"})\n",
    "    #sess.run(iterator_val.initializer,feed_dict={filenames_val:\"/media/antor/Files/ML/Papers/val_mfix.tfrecords\"})\n",
    "\n",
    "    mini_cost_val = 0.0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            \n",
    "            #temp_cost_val = sess.run(cost, feed_dict={M:mask_in_val,Y:label_in_val,is_training:False})\n",
    "            temp_cost_val = sess.run(cost, feed_dict={is_training:False})\n",
    "            #temp_cost_val = sess.run(cost_val)\n",
    "\n",
    "            mini_cost_val += temp_cost_val/break_v\n",
    "            \n",
    "            if counter_val%num_mini_val==0:\n",
    "                print(\"cost after epoch \" + str(counter_val/num_mini_val) + \": \" + str(mini_cost_val))\n",
    "                mini_cost_val =0.0 \n",
    "            counter_val = counter_val + 1\n",
    "            \n",
    "            if counter_val==break_v:\n",
    "                print(\"cost of val_set \" + \": \" + str(mini_cost_val))\n",
    "                break\n",
    "                       \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    \n",
    "    #save_path = saver.save(sess, \"/home/antor/Downloads/model_checkpoint/my_model_final.ckpt\")\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "i5w7yUdWOH1h",
    "outputId": "a3dd9e34-f947-4e9c-be22-f5437697dd5f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini batch cost of batch 10 is : 0.05782625079154968\n",
      "mini batch cost of batch 20 is : 0.04145779646933078\n",
      "mini batch cost of batch 30 is : 0.03315964080393314\n",
      "mini batch cost of batch 40 is : 0.041465912014245994\n",
      "mini batch cost of batch 50 is : 0.03498847968876362\n",
      "mini batch cost of batch 60 is : 0.042197620123624796\n",
      "mini batch cost of batch 70 is : 0.04350146856158972\n",
      "mini batch cost of batch 80 is : 0.04083496388047934\n",
      "mini batch cost of batch 90 is : 0.03331757467240095\n",
      "mini batch cost of batch 100 is : 0.030904060602188112\n",
      "mini batch cost of batch 110 is : 0.029777578078210354\n",
      "mini batch cost of batch 120 is : 0.03192330561578274\n",
      "mini batch cost of batch 130 is : 0.02675277292728424\n",
      "mini batch cost of batch 140 is : 0.024260314181447026\n",
      "mini batch cost of batch 150 is : 0.024045362882316117\n",
      "cost of val_set : 0.02080250035971403\n"
     ]
    }
   ],
   "source": [
    "model(learning_rate=.07,num_epochs=1,mini_size=2,break_t=150,break_v=25,pt_out=10,hole_pera=6.0,valid_pera=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Kq5tG1I0OH1o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "I82s6e35OH1t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "landsat_image _inpaintingerere.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
