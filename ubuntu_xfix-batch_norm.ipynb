{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "K0JU1wEzOH07",
    "outputId": "ec3065cd-da37-40ce-8763-cda85a3a6cf8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import cv2\n",
    "#import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")    #for tensorboard\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "agRyZL61OH1P"
   },
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    features = {\n",
    "                \"image_y\": tf.FixedLenFeature((), tf.string ),\n",
    "                \"image_m\": tf.FixedLenFeature((), tf.string )\n",
    "                #\"image_x\": tf.FixedLenFeature((), tf.string )\n",
    "                }\n",
    "\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    \n",
    "    image_y = tf.decode_raw(parsed_features[\"image_y\"],  tf.float64)\n",
    "    image_m = tf.decode_raw(parsed_features[\"image_m\"],  tf.float64)\n",
    "    \n",
    "    image_y = tf.reshape(image_y, [512,512,1])\n",
    "    image_m = tf.reshape(image_m, [512,512,1])\n",
    "    #image_x = tf.decode_raw(parsed_features[\"image_x\"],  tf.float64)\n",
    "    tf.summary.image(\"64_Y\",image_y,3)\n",
    "    tf.summary.image(\"64_M\",image_m,3)\n",
    "    \n",
    "    image_y = tf.cast(image_y,dtype=tf.float32)\n",
    "    image_m = tf.cast(image_m,dtype=tf.float32)\n",
    "    #image_x = tf.cast(image_x,dtype=tf.float32)\n",
    "    tf.summary.image(\"32_Y\",image_y,3)\n",
    "    tf.summary.image(\"32_M\",image_m,3)\n",
    "    \n",
    "    #image_y = tf.reshape(image_y, [512,512,1])\n",
    "    #image_m = tf.reshape(image_m, [512,512,1])\n",
    "    #image_x = tf.reshape(image_x, [512,512,1])\n",
    "    \n",
    "    return image_y,image_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(inputs, is_training, decay=.99, epsilon=0.00000001):\n",
    "    with tf.name_scope(\"batch_norm\") as scope:\n",
    "\n",
    "\n",
    "        scale = tf.get_variable(\"scale_BN\", (inputs.get_shape()[1:4]), initializer=tf.ones_initializer())\n",
    "        beta = tf.get_variable(\"beta_BN\", (inputs.get_shape()[1:4]), initializer=tf.zeros_initializer())\n",
    "        pop_mean = tf.get_variable(\"pop_mean\", (inputs.get_shape()[1:4]), initializer=tf.zeros_initializer(), trainable=False)\n",
    "        pop_var = tf.get_variable(\"pop_var\", (inputs.get_shape()[1:4]), initializer=tf.ones_initializer(), trainable=False)\n",
    "\n",
    "        mean = tf.cond(tf.cast(is_training,tf.bool), lambda: tf.nn.moments(inputs,[0])[0], lambda: tf.multiply(tf.ones(inputs.get_shape()[1:4]), pop_mean))\n",
    "        var = tf.cond(tf.cast(is_training,tf.bool), lambda: tf.nn.moments(inputs,[0])[1], lambda: tf.multiply(tf.ones(inputs.get_shape()[-1]), pop_var))\n",
    "        train_mean = tf.cond(tf.cast(is_training,tf.bool), lambda:tf.assign(pop_mean, pop_mean*decay+mean*(1-decay)),lambda:tf.zeros(1))\n",
    "        train_var = tf.cond(tf.cast(is_training,tf.bool),lambda:tf.assign(pop_var, pop_var*decay+var*(1-decay)),lambda:tf.zeros(1))\n",
    "\n",
    "        with tf.control_dependencies([train_mean, train_var]):\n",
    "            return tf.nn.batch_normalization(inputs, mean, var, beta, scale, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZZqe6faCOH1R"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def partial_conv(pixel, mask,is_training, kernel_size, filter_numbers, stride, batch_n, nonlinearity, trans):\n",
    "\n",
    "    with tf.name_scope(\"part_conv\") as scope:\n",
    "        kernel_h = kernel_size[0]\n",
    "        kernel_w = kernel_size[1]\n",
    "        if trans==True:\n",
    "            kernel_d = filter_numbers\n",
    "            kernel_o = pixel.get_shape().as_list()[3]\n",
    "        elif trans==False:\n",
    "            kernel_d = pixel.get_shape().as_list()[3]\n",
    "            kernel_o = filter_numbers\n",
    "        elif trans==\"same_pad\":\n",
    "            #kernel_d = pixel.get_shape().as_list()[3]\n",
    "            #kernel_o = filter_numbers\n",
    "            kernel_d = filter_numbers\n",
    "            kernel_o = pixel.get_shape().as_list()[3]\n",
    "            \n",
    "            \n",
    "        W = tf.get_variable('Weights', (kernel_h, kernel_w, kernel_d, kernel_o),\n",
    "                            initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "        \n",
    "        \n",
    "        W1 = tf.ones((kernel_h, kernel_w, kernel_d, kernel_o), name='Weights_mask')\n",
    "\n",
    "        Z1 = tf.multiply(pixel, mask, name=\"element_op\")\n",
    "\n",
    "        if trans==True:\n",
    "            #need to fix for variable last batch size. The last mini_batch will be of different size most of the time\n",
    "            out_shape_list = pixel.get_shape().as_list()\n",
    "            out_shape_list[1] = pixel.get_shape().as_list()[1] + 2\n",
    "            out_shape_list[2] = pixel.get_shape().as_list()[2] + 2\n",
    "            out_shape_list[3] = filter_numbers\n",
    "            out_shape = tf.constant(out_shape_list)\n",
    "            #out_shape = tf.TensorShape(out_shape_list)\n",
    "            #out_shape = tf.cast(out_shape,tf.int32)\n",
    "            prime_conv = tf.nn.conv2d_transpose(Z1, W,out_shape, strides=stride, padding=\"VALID\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d_transpose(mask, W1,output_shape=tf.TensorShape(out_shape_list), strides=stride, padding=\"VALID\", name=\"sec_conv\")\n",
    "        elif trans==False:\n",
    "            prime_conv = tf.nn.conv2d(Z1, W, strides=stride, padding=\"VALID\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d(mask, W1, strides=stride, padding=\"VALID\", name=\"sec_conv\")\n",
    "        elif trans==\"same_pad\":\n",
    "            #prime_conv = tf.nn.conv2d(Z1, W, strides=stride, padding=\"SAME\", name=\"prime_conv\")\n",
    "            #sec_conv = tf.nn.conv2d(mask, W1, strides=stride, padding=\"SAME\", name=\"sec_conv\")\n",
    "            out_shape_list = pixel.get_shape().as_list()\n",
    "            out_shape_list[1] = pixel.get_shape().as_list()[1] \n",
    "            out_shape_list[2] = pixel.get_shape().as_list()[2] \n",
    "            out_shape_list[3] = filter_numbers\n",
    "            out_shape = tf.constant(out_shape_list)\n",
    "            prime_conv = tf.nn.conv2d_transpose(Z1, W,out_shape, strides=stride, padding=\"SAME\", name=\"prime_conv\")\n",
    "            sec_conv = tf.nn.conv2d_transpose(mask, W1,output_shape=tf.TensorShape(out_shape_list), strides=stride, padding=\"SAME\", name=\"sec_conv\")\n",
    "\n",
    "\n",
    "        inver_sum = tf.divide(tf.constant(1.0), sec_conv)\n",
    "        clean_sum = tf.where(tf.is_inf(inver_sum), tf.zeros_like(inver_sum), inver_sum)\n",
    "\n",
    "        weighted_pixel = tf.multiply(prime_conv, clean_sum, name=\"multi_inver_sum\")\n",
    "        up_mask = tf.where(tf.not_equal(sec_conv, tf.constant(0.0)),tf.ones_like(sec_conv),sec_conv)\n",
    "\n",
    "        #normalized_out = tf.cond(tf.cast(batch_n,tf.bool), lambda:batch_norm(weighted_pixel, is_training), lambda:weighted_pixel)\n",
    "        B = tf.get_variable('Biases',(1,weighted_pixel.get_shape()[1],weighted_pixel.get_shape()[2],weighted_pixel.get_shape()[3]),\n",
    "                            initializer=tf.constant_initializer(.01))\n",
    "        \n",
    "        normalized_out = tf.add(weighted_pixel,B)\n",
    "        #normalized_out = weighted_pixel\n",
    "        \n",
    "        if nonlinearity==\"relu\":\n",
    "            up_pixel = tf.nn.relu(normalized_out, name=\"relu\")\n",
    "        elif nonlinearity==\"leaky_relu\":\n",
    "            up_pixel = tf.nn.leaky_relu(normalized_out, name=\"leaky_relu\")\n",
    "        elif nonlinearity==\"none\":\n",
    "            up_pixel = normalized_out\n",
    "            #up_pixel = tf.sigmoid(normalized_out)\n",
    "            #up_pixel = tf.nn.relu(normalized_out, name=\"relu\")\n",
    "            \n",
    "        tf.summary.histogram(\"weights\", W)    \n",
    "        tf.summary.histogram(\"biases\", B)   \n",
    "        tf.summary.histogram(\"activations\", up_pixel)   \n",
    "        \n",
    "        return up_pixel, up_mask\n",
    "    \n",
    "\n",
    "\n",
    "def place_holders(mini_size,height, width, channels):\n",
    "    #X = tf.placeholder(tf.float32, shape=(mini_size, height, width, channels))\n",
    "    Y = tf.placeholder(tf.float32, shape=(mini_size, height, width, channels))\n",
    "    M = tf.placeholder(tf.float32, shape=(mini_size, height, width, channels))\n",
    "    return M ,Y\n",
    "\n",
    "\n",
    "def near_up_sampling(pixel, mask, output_size):\n",
    "    with tf.name_scope(\"nearest_up\") as scope:\n",
    "        up_pixel = tf.image.resize_nearest_neighbor(pixel, size=output_size, name=\"nearest_pixel_up\")\n",
    "        up_mask = tf.image.resize_nearest_neighbor(pixel, size=output_size, name=\"nearest_mask_up\")\n",
    "        return up_pixel, up_mask\n",
    "\n",
    "def concat(near_pixel, pconv_pixel, near_mask, pconv_mask):\n",
    "    with tf.name_scope(\"concatenation\") as scope:\n",
    "        up_pixel = tf.concat([pconv_pixel, near_pixel], axis=3)\n",
    "        up_mask = tf.concat([pconv_mask,near_mask], axis=3)\n",
    "        return up_pixel, up_mask\n",
    "\n",
    "def decoding_layer(pixel_in,mask_in,is_training, output_size_in, pconv_pixel1, pconv_mask1, filter_numbers1):\n",
    "    with tf.name_scope(\"decoding\") as scope:\n",
    "        near_pixel1,near_mask1 = near_up_sampling(pixel_in,mask_in,output_size_in)\n",
    "        concat_pixel,concat_mask = concat(near_pixel1, pconv_pixel1, near_mask1, pconv_mask1)\n",
    "        pixel_out,mask_out = partial_conv(concat_pixel,concat_mask,is_training,[3,3],filter_numbers1,[1,1,1,1],\n",
    "                                        True,\"leaky_relu\",trans=True)\n",
    "        return pixel_out,mask_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mFUVWDrVOH1V"
   },
   "outputs": [],
   "source": [
    "def forward_prop(is_training, pixel, mask):\n",
    "\n",
    "    with tf.variable_scope(\"PConv1\") as scope:\n",
    "        p_out1,m_out1 = partial_conv(pixel,mask,is_training,kernel_size=[7,7],filter_numbers=64,stride=[1,2,2,1],\n",
    "                                    batch_n=False,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv2\") as scope:\n",
    "        p_out2,m_out2 = partial_conv(p_out1,m_out1,is_training,kernel_size=[5,5],filter_numbers=128,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv3\") as scope:\n",
    "        p_out3,m_out3 = partial_conv(p_out2,m_out2,is_training,kernel_size=[5,5],filter_numbers=256,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv4\") as scope:\n",
    "        p_out4,m_out4 = partial_conv(p_out3,p_out3,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv5\") as scope:\n",
    "        p_out5,m_out5 = partial_conv(p_out4,m_out4,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv6\") as scope:\n",
    "        p_out6,m_out6 = partial_conv(p_out5,m_out5,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,2,2,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv7\") as scope:\n",
    "        p_out7,m_out7 = partial_conv(p_out6,m_out6,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,1,1,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"PConv8\") as scope:\n",
    "        p_out8,m_out8 = partial_conv(p_out7,m_out7,is_training,kernel_size=[3,3],filter_numbers=512,stride=[1,1,1,1],\n",
    "                                    batch_n=True,nonlinearity=\"relu\",trans=False)\n",
    "    with tf.variable_scope(\"decoding9\") as scope:\n",
    "        p_out9,m_out9 = decoding_layer(p_out8,m_out8,is_training,(p_out7.get_shape().as_list()[1],p_out7.get_shape().as_list()[2]),\n",
    "                                        p_out7,m_out7,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding10\") as scope:\n",
    "        p_out10,m_out10 = decoding_layer(p_out9,m_out9,is_training,(p_out6.get_shape().as_list()[1],p_out6.get_shape().as_list()[2]),\n",
    "                                        p_out6,m_out6,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding11\") as scope:\n",
    "        p_out11,m_out11 = decoding_layer(p_out10,m_out10,is_training,(p_out5.get_shape().as_list()[1],p_out5.get_shape().as_list()[2]),\n",
    "                                        p_out5,m_out5,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding12\") as scope:\n",
    "        p_out12,m_out12 = decoding_layer(p_out11,m_out11,is_training,(p_out4.get_shape().as_list()[1],p_out4.get_shape().as_list()[2]),\n",
    "                                        p_out4,m_out4,filter_numbers1=512)\n",
    "\n",
    "    with tf.variable_scope(\"decoding13\") as scope:\n",
    "        p_out13,m_out13 = decoding_layer(p_out12,m_out12,is_training,(p_out3.get_shape().as_list()[1],p_out3.get_shape().as_list()[2]),\n",
    "                                        p_out3,m_out3,filter_numbers1=256)\n",
    "\n",
    "    with tf.variable_scope(\"decoding14\") as scope:\n",
    "        p_out14,m_out14 = decoding_layer(p_out13,m_out13,is_training,(p_out2.get_shape().as_list()[1],p_out2.get_shape().as_list()[2]),\n",
    "                                        p_out2,m_out2,filter_numbers1=128)\n",
    "\n",
    "    with tf.variable_scope(\"decoding15\") as scope:\n",
    "        p_out15,m_out15 = decoding_layer(p_out14,m_out14,is_training,(p_out1.get_shape().as_list()[1],p_out1.get_shape().as_list()[2]),\n",
    "                                        p_out1,m_out1,filter_numbers1=64)\n",
    "\n",
    "    #with tf.variable_scope(\"decoding16\") as scope:\n",
    "    #    p_out16,m_out16 = decoding_layer(p_out15,m_out15,is_training,(pixel.get_shape().as_list()[1],pixel.get_shape().as_list()[2]),\n",
    "    #                                    pixel,mask,filter_numbers1=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(\"decoding16\") as scope:\n",
    "        near_pixel1,near_mask1 = near_up_sampling(p_out15,m_out15,(pixel.get_shape().as_list()[1],pixel.get_shape().as_list()[2]))\n",
    "        concat_pixel,concat_mask = concat(near_pixel1, pixel, near_mask1, mask)\n",
    "        pixel_out,mask_out = partial_conv(concat_pixel,concat_mask,is_training,[3,3],filter_numbers=1,stride=[1,1,1,1],\n",
    "                                        batch_n=False,nonlinearity=\"none\",trans=\"same_pad\")\n",
    "        return pixel_out,mask_out\n",
    "\n",
    "\n",
    "\n",
    "def compute_cost(pixel_gt,mask_gt,pixel_pre,hole_pera):\n",
    "    loss_valid = tf.losses.absolute_difference(tf.multiply(pixel_gt,mask_gt),tf.multiply(pixel_pre,mask_gt), weights=1.0,\n",
    "                                                reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)\n",
    "    loss_hole = tf.losses.absolute_difference(tf.multiply(pixel_gt,(1-mask_gt)),tf.multiply(pixel_pre,(1-mask_gt)), weights=1.0,\n",
    "                                                reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)\n",
    "\n",
    "    total_loss = (loss_valid + tf.multiply(hole_pera,loss_hole))/7.0\n",
    "    \n",
    "    tf.summary.scalar('loss',total_loss)\n",
    "   \n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lgvAO8mGOH1d"
   },
   "outputs": [],
   "source": [
    "def model(learning_rate,num_epochs,mini_size,break_t,break_v,pt_out):\n",
    "    #ops.reset_default_graph()\n",
    "#     m = x_train.shape[0]\n",
    "#     h = x_train.shape[1]\n",
    "#     w = x_train.shape[2]\n",
    "#     c = x_train.shape[3]\n",
    "    m = 9882\n",
    "    #m = 8\n",
    "    h = 512\n",
    "    w = 512\n",
    "    c = 1\n",
    "    \n",
    "    m_val_size = 1098\n",
    "    #m_val_size = 2\n",
    "    costs = []\n",
    "\n",
    "    M,Y = place_holders(mini_size,h, w, c)\n",
    "    \n",
    "    tf.summary.image(\"input_Y\",Y,3)\n",
    "    tf.summary.image(\"input_M\",M,3)\n",
    "    \n",
    "    is_training = tf.placeholder(tf.bool,name=\"training\")\n",
    "    \n",
    "    pixel_out, mask_out = forward_prop(is_training,pixel=Y, mask=M)\n",
    "\n",
    "    cost = compute_cost(pixel_gt=Y, mask_gt=M, pixel_pre=pixel_out, hole_pera=6.0)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    #data_x = tf.placeholder(x_train.dtype, x_train.shape)\n",
    "    #data_m = tf.placeholder(m_train.dtype, m_train.shape)\n",
    "    #data_y = tf.placeholder(y_train.dtype, y_train.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    filenames = \"/media/antor/Files/ML/Papers/train_new.tfrecords\"\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    #dataset = tf.data.Dataset.from_tensor_slices((data_x, data_m, data_y))\n",
    "    \n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.shuffle(20)\n",
    "    dataset = dataset.batch(mini_size)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "    num_mini = int(m/mini_size)          #must keep this fully divided and num_mini output as int pretty sure it doesn't need\n",
    "                                    #to be an int\n",
    "    \n",
    "    merge_sum = tf.summary.merge_all()\n",
    "    #l1_summary = tf.summary.scalar('L1', cost)            #for tensorboard\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())   #for tensorboard\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "    #session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    #sess.run(iterator.initializer, feed_dict={data_x:x_train, data_m:m_train, data_y:y_train})\n",
    "    sess.run(iterator.initializer)\n",
    "    mini_cost = 0.0\n",
    "    counter = 1\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            pix_gt, mask_in = sess.run(next_element)\n",
    "            pix_gt = tf.reshape(pix_gt,[mini_size,512,512,1])\n",
    "            mask_in = tf.reshape(mask_in,[mini_size,512,512,1])\n",
    "            #pix_in = tf.reshape(pix_in,[mini_size,512,512,1])\n",
    "            \n",
    "            pix_gt = pix_gt.eval(session=sess)\n",
    "            mask_in = mask_in.eval(session=sess)\n",
    "            #pix_in = pix_in.eval(session=sess)\n",
    "            #print( pix_gt)\n",
    "            #print( mask_in)\n",
    "            #print( pix_in)\n",
    "            #pixel_out, mask_out = forward_prop(True,pixel=label_in, mask=mask_in)\n",
    "\n",
    "            #cost = compute_cost(pixel_gt=pix_in, mask_gt=mask_in, pixel_pre=pixel_out, hole_pera=6.0)\n",
    "\n",
    "            #optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "            \n",
    "            _ , temp_cost = sess.run([optimizer,cost],feed_dict={M:mask_in, Y:pix_gt, is_training:True})\n",
    "            #_ , temp_cost = sess.run([optimizer,cost])\n",
    "            \n",
    "            #mini_cost += temp_cost/num_mini\n",
    "            mini_cost += temp_cost/pt_out\n",
    "            \n",
    "            if counter%5 == 0:\n",
    "                s = sess.run(merge_sum, feed_dict={M:mask_in, Y:pix_gt, is_training:True})\n",
    "                file_writer.add_summary(s,counter)\n",
    "            \n",
    "            if counter%num_mini==0:\n",
    "                print(\"cost after epoch \" + str(counter/num_mini) + \": \" + str(mini_cost))\n",
    "                mini_cost =0.0 \n",
    "            #print(\"cost after epoch \" + str(counter/num_mini) + \": \" + str(mini_cost))\n",
    "            \n",
    "#             if counter%50==0:         #for tensorboard\n",
    "#                 summary_str = l1_summary.eval(session=sess,feed_dict={M:mask_in, Y:pix_gt, is_training:True})\n",
    "#                 #step = int(counter%num_mini) * n_batches + batch_index\n",
    "#                 file_writer.add_summary(summary_str, counter)\n",
    "            \n",
    "            #if counter%1==0:\n",
    "            #    print(\"mini batch cost of batch \" + str(counter) + \" is : \" + str(temp_cost))\n",
    "            if counter%pt_out==0:\n",
    "                print(\"mini batch cost of batch \" + str(counter) + \" is : \" + str(mini_cost))\n",
    "                mini_cost =0.0 \n",
    "            \n",
    "            if counter==break_t:\n",
    "                break\n",
    "            \n",
    "            counter = counter + 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            #counter = counter + 1\n",
    "            #print(\"cost after epoch \" + str(counter) + \": \" + str(mini_cost))\n",
    "            #mini_cost = 0.0\n",
    "            break\n",
    "    \n",
    "    file_writer.close()            #for tensorboard\n",
    "    #data_x_val = tf.placeholder(x_val.dtype, x_val.shape)\n",
    "    #m_val = m_val.astype(float)\n",
    "    #data_m_val = tf.placeholder(m_val.dtype, m_val.shape)\n",
    "    #data_y_val = tf.placeholder(y_val.dtype, y_val.shape)\n",
    "    \n",
    "    filenames_val = \"/media/antor/Files/ML/Papers/val_new.tfrecords\"\n",
    "    dataset_val = tf.data.TFRecordDataset(filenames_val)\n",
    "    dataset_val = dataset_val.map(_parse_function)\n",
    "    \n",
    "    #dataset_val = tf.data.Dataset.from_tensor_slices((data_x_val,data_m_val,data_y_val))\n",
    "    dataset_val = dataset_val.shuffle(20)\n",
    "    dataset_val = dataset_val.batch(mini_size)\n",
    "    \n",
    "    iterator_val = dataset_val.make_initializable_iterator()\n",
    "    next_element_val = iterator_val.get_next()\n",
    "    num_mini_val = int(m_val_size/mini_size)\n",
    "\n",
    "    counter_val = 1\n",
    "    #sess.run(iterator_val.initializer, feed_dict={data_x_val:x_val,data_m_val:m_val,data_y_val:y_val})\n",
    "    sess.run(iterator_val.initializer)\n",
    "    mini_cost_val = 0.0\n",
    "    #break_num = 40\n",
    "    while True:\n",
    "        try:\n",
    "            label_in_val, mask_in_val = sess.run(next_element_val)\n",
    "            #pix_in_val = tf.reshape(pix_in_val,[mini_size,512,512,1])\n",
    "            mask_in_val = tf.reshape(mask_in_val,[mini_size,512,512,1])\n",
    "            label_in_val = tf.reshape(label_in_val,[mini_size,512,512,1])\n",
    "            #pix_in_val = pix_in_val.eval(session=sess)\n",
    "            mask_in_val = mask_in_val.eval(session=sess)\n",
    "            label_in_val = label_in_val.eval(session=sess)\n",
    "            \n",
    "            temp_cost_val = sess.run(cost, feed_dict={M:mask_in_val,Y:label_in_val,is_training:False})\n",
    "            \n",
    "            \n",
    "            mini_cost_val += temp_cost_val/break_v\n",
    "            \n",
    "            if counter_val%num_mini_val==0:\n",
    "                print(\"cost after epoch \" + str(counter_val/num_mini_val) + \": \" + str(mini_cost_val))\n",
    "                mini_cost_val =0.0 \n",
    "            counter_val = counter_val + 1\n",
    "            \n",
    "            if counter_val==break_v:\n",
    "                print(\"cost of val_set \" + \": \" + str(mini_cost_val))\n",
    "                break\n",
    "            \n",
    "            \n",
    "        except tf.errors.OutOfRangeError:\n",
    "\n",
    "            #print(\"validation cost after epoch \" + \"1\" + \": \" + str(mini_cost_val))\n",
    "\n",
    "            break\n",
    "    \n",
    "    #save_path = saver.save(sess, \"/home/antor/Downloads/model_checkpoint/my_model_final.ckpt\")\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "i5w7yUdWOH1h",
    "outputId": "a3dd9e34-f947-4e9c-be22-f5437697dd5f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini batch cost of batch 10 is : 0.27852838188409806\n",
      "mini batch cost of batch 20 is : 0.11842885017395019\n",
      "mini batch cost of batch 30 is : 0.08787534832954406\n",
      "mini batch cost of batch 40 is : 0.07339720837771892\n",
      "mini batch cost of batch 50 is : 0.07144180946052076\n",
      "mini batch cost of batch 60 is : 0.05750089175999164\n",
      "mini batch cost of batch 70 is : 0.06498565673828126\n",
      "mini batch cost of batch 80 is : 0.05042915306985378\n",
      "mini batch cost of batch 90 is : 0.059459491074085234\n",
      "mini batch cost of batch 100 is : 0.06574115678668023\n",
      "cost of val_set : 0.05998010262846946\n"
     ]
    }
   ],
   "source": [
    "model(learning_rate=.055,num_epochs=1,mini_size=2,break_t=100,break_v=10,pt_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Kq5tG1I0OH1o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "I82s6e35OH1t"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "landsat_image _inpaintingerere.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
